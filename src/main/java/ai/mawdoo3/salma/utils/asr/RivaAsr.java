// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: riva/riva_asr.proto

package ai.mawdoo3.salma.utils.asr;


public final class RivaAsr {
  private RivaAsr() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface RecognizeRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognizeRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return Whether the config field is set.
     */
    boolean hasConfig();
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return The config.
     */
    RecognitionConfig getConfig();
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    RecognitionConfigOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * The raw audio data to be processed. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio = 2;</code>
     * @return The audio.
     */
    com.google.protobuf.ByteString getAudio();
  }
  /**
   * <pre>
   *
   * RecognizeRequest is used for batch processing of a single audio recording.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognizeRequest}
   */
  public static final class RecognizeRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognizeRequest)
      RecognizeRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecognizeRequest.newBuilder() to construct.
    private RecognizeRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognizeRequest() {
      audio_ = com.google.protobuf.ByteString.EMPTY;
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new RecognizeRequest();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              RecognizeRequest.class, Builder.class);
    }

    public static final int CONFIG_FIELD_NUMBER = 1;
    private RecognitionConfig config_;
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return Whether the config field is set.
     */
    @Override
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return The config.
     */
    @Override
    public RecognitionConfig getConfig() {
      return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    @Override
    public RecognitionConfigOrBuilder getConfigOrBuilder() {
      return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
    }

    public static final int AUDIO_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString audio_ = com.google.protobuf.ByteString.EMPTY;
    /**
     * <pre>
     * The raw audio data to be processed. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio = 2;</code>
     * @return The audio.
     */
    @Override
    public com.google.protobuf.ByteString getAudio() {
      return audio_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (config_ != null) {
        output.writeMessage(1, getConfig());
      }
      if (!audio_.isEmpty()) {
        output.writeBytes(2, audio_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getConfig());
      }
      if (!audio_.isEmpty()) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, audio_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof RecognizeRequest)) {
        return super.equals(obj);
      }
      RecognizeRequest other = (RecognizeRequest) obj;

      if (hasConfig() != other.hasConfig()) return false;
      if (hasConfig()) {
        if (!getConfig()
            .equals(other.getConfig())) return false;
      }
      if (!getAudio()
          .equals(other.getAudio())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + AUDIO_FIELD_NUMBER;
      hash = (53 * hash) + getAudio().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static RecognizeRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognizeRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static RecognizeRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static RecognizeRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static RecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(RecognizeRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *
     * RecognizeRequest is used for batch processing of a single audio recording.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognizeRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognizeRequest)
        RecognizeRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                RecognizeRequest.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.RecognizeRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        config_ = null;
        if (configBuilder_ != null) {
          configBuilder_.dispose();
          configBuilder_ = null;
        }
        audio_ = com.google.protobuf.ByteString.EMPTY;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
      }

      @Override
      public RecognizeRequest getDefaultInstanceForType() {
        return RecognizeRequest.getDefaultInstance();
      }

      @Override
      public RecognizeRequest build() {
        RecognizeRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public RecognizeRequest buildPartial() {
        RecognizeRequest result = new RecognizeRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(RecognizeRequest result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.config_ = configBuilder_ == null
              ? config_
              : configBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.audio_ = audio_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof RecognizeRequest) {
          return mergeFrom((RecognizeRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(RecognizeRequest other) {
        if (other == RecognizeRequest.getDefaultInstance()) return this;
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (other.getAudio() != com.google.protobuf.ByteString.EMPTY) {
          setAudio(other.getAudio());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 18: {
                audio_ = input.readBytes();
                bitField0_ |= 0x00000002;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private RecognitionConfig config_;
      private com.google.protobuf.SingleFieldBuilderV3<
          RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder> configBuilder_;
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       * @return Whether the config field is set.
       */
      public boolean hasConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       * @return The config.
       */
      public RecognitionConfig getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
        } else {
          configBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(
          RecognitionConfig.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder mergeConfig(RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            config_ != null &&
            config_ != RecognitionConfig.getDefaultInstance()) {
            getConfigBuilder().mergeFrom(value);
          } else {
            config_ = value;
          }
        } else {
          configBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder clearConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        config_ = null;
        if (configBuilder_ != null) {
          configBuilder_.dispose();
          configBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public RecognitionConfig.Builder getConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public RecognitionConfigOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              RecognitionConfig.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder>
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private com.google.protobuf.ByteString audio_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio = 2;</code>
       * @return The audio.
       */
      @Override
      public com.google.protobuf.ByteString getAudio() {
        return audio_;
      }
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio = 2;</code>
       * @param value The audio to set.
       * @return This builder for chaining.
       */
      public Builder setAudio(com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        audio_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudio() {
        bitField0_ = (bitField0_ & ~0x00000002);
        audio_ = getDefaultInstance().getAudio();
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognizeRequest)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognizeRequest)
    private static final RecognizeRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new RecognizeRequest();
    }

    public static RecognizeRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognizeRequest>
        PARSER = new com.google.protobuf.AbstractParser<RecognizeRequest>() {
      @Override
      public RecognizeRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<RecognizeRequest> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<RecognizeRequest> getParserForType() {
      return PARSER;
    }

    @Override
    public RecognizeRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognizeRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognizeRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     * @return Whether the streamingConfig field is set.
     */
    boolean hasStreamingConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     * @return The streamingConfig.
     */
    StreamingRecognitionConfig getStreamingConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder();

    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return Whether the audioContent field is set.
     */
    boolean hasAudioContent();
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return The audioContent.
     */
    com.google.protobuf.ByteString getAudioContent();

    StreamingRecognizeRequest.StreamingRequestCase getStreamingRequestCase();
  }
  /**
   * <pre>
   *
   * A StreamingRecognizeRequest is used to configure and stream audio content to the
   * Riva ASR Service. The first message sent must include only a StreamingRecognitionConfig.
   * Subsequent messages sent in the stream must contain only raw bytes of the audio
   * to be recognized.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeRequest}
   */
  public static final class StreamingRecognizeRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognizeRequest)
      StreamingRecognizeRequestOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingRecognizeRequest.newBuilder() to construct.
    private StreamingRecognizeRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognizeRequest() {
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingRecognizeRequest();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              StreamingRecognizeRequest.class, Builder.class);
    }

    private int streamingRequestCase_ = 0;
    @SuppressWarnings("serial")
    private Object streamingRequest_;
    public enum StreamingRequestCase
        implements com.google.protobuf.Internal.EnumLite,
            InternalOneOfEnum {
      STREAMING_CONFIG(1),
      AUDIO_CONTENT(2),
      STREAMINGREQUEST_NOT_SET(0);
      private final int value;
      private StreamingRequestCase(int value) {
        this.value = value;
      }
      /**
       * @param value The number of the enum to look for.
       * @return The enum associated with the given number.
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static StreamingRequestCase valueOf(int value) {
        return forNumber(value);
      }

      public static StreamingRequestCase forNumber(int value) {
        switch (value) {
          case 1: return STREAMING_CONFIG;
          case 2: return AUDIO_CONTENT;
          case 0: return STREAMINGREQUEST_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public StreamingRequestCase
    getStreamingRequestCase() {
      return StreamingRequestCase.forNumber(
          streamingRequestCase_);
    }

    public static final int STREAMING_CONFIG_FIELD_NUMBER = 1;
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     * @return Whether the streamingConfig field is set.
     */
    @Override
    public boolean hasStreamingConfig() {
      return streamingRequestCase_ == 1;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     * @return The streamingConfig.
     */
    @Override
    public StreamingRecognitionConfig getStreamingConfig() {
      if (streamingRequestCase_ == 1) {
         return (StreamingRecognitionConfig) streamingRequest_;
      }
      return StreamingRecognitionConfig.getDefaultInstance();
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    @Override
    public StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder() {
      if (streamingRequestCase_ == 1) {
         return (StreamingRecognitionConfig) streamingRequest_;
      }
      return StreamingRecognitionConfig.getDefaultInstance();
    }

    public static final int AUDIO_CONTENT_FIELD_NUMBER = 2;
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return Whether the audioContent field is set.
     */
    @Override
    public boolean hasAudioContent() {
      return streamingRequestCase_ == 2;
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>bytes audio_content = 2;</code>
     * @return The audioContent.
     */
    @Override
    public com.google.protobuf.ByteString getAudioContent() {
      if (streamingRequestCase_ == 2) {
        return (com.google.protobuf.ByteString) streamingRequest_;
      }
      return com.google.protobuf.ByteString.EMPTY;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (streamingRequestCase_ == 1) {
        output.writeMessage(1, (StreamingRecognitionConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        output.writeBytes(
            2, (com.google.protobuf.ByteString) streamingRequest_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (streamingRequestCase_ == 1) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, (StreamingRecognitionConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(
              2, (com.google.protobuf.ByteString) streamingRequest_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof StreamingRecognizeRequest)) {
        return super.equals(obj);
      }
      StreamingRecognizeRequest other = (StreamingRecognizeRequest) obj;

      if (!getStreamingRequestCase().equals(other.getStreamingRequestCase())) return false;
      switch (streamingRequestCase_) {
        case 1:
          if (!getStreamingConfig()
              .equals(other.getStreamingConfig())) return false;
          break;
        case 2:
          if (!getAudioContent()
              .equals(other.getAudioContent())) return false;
          break;
        case 0:
        default:
      }
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      switch (streamingRequestCase_) {
        case 1:
          hash = (37 * hash) + STREAMING_CONFIG_FIELD_NUMBER;
          hash = (53 * hash) + getStreamingConfig().hashCode();
          break;
        case 2:
          hash = (37 * hash) + AUDIO_CONTENT_FIELD_NUMBER;
          hash = (53 * hash) + getAudioContent().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static StreamingRecognizeRequest parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeRequest parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognizeRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static StreamingRecognizeRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static StreamingRecognizeRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static StreamingRecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(StreamingRecognizeRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *
     * A StreamingRecognizeRequest is used to configure and stream audio content to the
     * Riva ASR Service. The first message sent must include only a StreamingRecognitionConfig.
     * Subsequent messages sent in the stream must contain only raw bytes of the audio
     * to be recognized.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognizeRequest)
        StreamingRecognizeRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                StreamingRecognizeRequest.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.StreamingRecognizeRequest.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (streamingConfigBuilder_ != null) {
          streamingConfigBuilder_.clear();
        }
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
      }

      @Override
      public StreamingRecognizeRequest getDefaultInstanceForType() {
        return StreamingRecognizeRequest.getDefaultInstance();
      }

      @Override
      public StreamingRecognizeRequest build() {
        StreamingRecognizeRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public StreamingRecognizeRequest buildPartial() {
        StreamingRecognizeRequest result = new StreamingRecognizeRequest(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        buildPartialOneofs(result);
        onBuilt();
        return result;
      }

      private void buildPartial0(StreamingRecognizeRequest result) {
        int from_bitField0_ = bitField0_;
      }

      private void buildPartialOneofs(StreamingRecognizeRequest result) {
        result.streamingRequestCase_ = streamingRequestCase_;
        result.streamingRequest_ = this.streamingRequest_;
        if (streamingRequestCase_ == 1 &&
            streamingConfigBuilder_ != null) {
          result.streamingRequest_ = streamingConfigBuilder_.build();
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof StreamingRecognizeRequest) {
          return mergeFrom((StreamingRecognizeRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(StreamingRecognizeRequest other) {
        if (other == StreamingRecognizeRequest.getDefaultInstance()) return this;
        switch (other.getStreamingRequestCase()) {
          case STREAMING_CONFIG: {
            mergeStreamingConfig(other.getStreamingConfig());
            break;
          }
          case AUDIO_CONTENT: {
            setAudioContent(other.getAudioContent());
            break;
          }
          case STREAMINGREQUEST_NOT_SET: {
            break;
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getStreamingConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                streamingRequestCase_ = 1;
                break;
              } // case 10
              case 18: {
                streamingRequest_ = input.readBytes();
                streamingRequestCase_ = 2;
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int streamingRequestCase_ = 0;
      private Object streamingRequest_;
      public StreamingRequestCase
          getStreamingRequestCase() {
        return StreamingRequestCase.forNumber(
            streamingRequestCase_);
      }

      public Builder clearStreamingRequest() {
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        onChanged();
        return this;
      }

      private int bitField0_;

      private com.google.protobuf.SingleFieldBuilderV3<
          StreamingRecognitionConfig, StreamingRecognitionConfig.Builder, StreamingRecognitionConfigOrBuilder> streamingConfigBuilder_;
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       * @return Whether the streamingConfig field is set.
       */
      @Override
      public boolean hasStreamingConfig() {
        return streamingRequestCase_ == 1;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       * @return The streamingConfig.
       */
      @Override
      public StreamingRecognitionConfig getStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            return (StreamingRecognitionConfig) streamingRequest_;
          }
          return StreamingRecognitionConfig.getDefaultInstance();
        } else {
          if (streamingRequestCase_ == 1) {
            return streamingConfigBuilder_.getMessage();
          }
          return StreamingRecognitionConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(StreamingRecognitionConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          streamingRequest_ = value;
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(value);
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(
          StreamingRecognitionConfig.Builder builderForValue) {
        if (streamingConfigBuilder_ == null) {
          streamingRequest_ = builderForValue.build();
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(builderForValue.build());
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder mergeStreamingConfig(StreamingRecognitionConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1 &&
              streamingRequest_ != StreamingRecognitionConfig.getDefaultInstance()) {
            streamingRequest_ = StreamingRecognitionConfig.newBuilder((StreamingRecognitionConfig) streamingRequest_)
                .mergeFrom(value).buildPartial();
          } else {
            streamingRequest_ = value;
          }
          onChanged();
        } else {
          if (streamingRequestCase_ == 1) {
            streamingConfigBuilder_.mergeFrom(value);
          } else {
            streamingConfigBuilder_.setMessage(value);
          }
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder clearStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
            onChanged();
          }
        } else {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
          }
          streamingConfigBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public StreamingRecognitionConfig.Builder getStreamingConfigBuilder() {
        return getStreamingConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      @Override
      public StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder() {
        if ((streamingRequestCase_ == 1) && (streamingConfigBuilder_ != null)) {
          return streamingConfigBuilder_.getMessageOrBuilder();
        } else {
          if (streamingRequestCase_ == 1) {
            return (StreamingRecognitionConfig) streamingRequest_;
          }
          return StreamingRecognitionConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>.nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          StreamingRecognitionConfig, StreamingRecognitionConfig.Builder, StreamingRecognitionConfigOrBuilder>
          getStreamingConfigFieldBuilder() {
        if (streamingConfigBuilder_ == null) {
          if (!(streamingRequestCase_ == 1)) {
            streamingRequest_ = StreamingRecognitionConfig.getDefaultInstance();
          }
          streamingConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              StreamingRecognitionConfig, StreamingRecognitionConfig.Builder, StreamingRecognitionConfigOrBuilder>(
                  (StreamingRecognitionConfig) streamingRequest_,
                  getParentForChildren(),
                  isClean());
          streamingRequest_ = null;
        }
        streamingRequestCase_ = 1;
        onChanged();
        return streamingConfigBuilder_;
      }

      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return Whether the audioContent field is set.
       */
      public boolean hasAudioContent() {
        return streamingRequestCase_ == 2;
      }
      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return The audioContent.
       */
      public com.google.protobuf.ByteString getAudioContent() {
        if (streamingRequestCase_ == 2) {
          return (com.google.protobuf.ByteString) streamingRequest_;
        }
        return com.google.protobuf.ByteString.EMPTY;
      }
      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @param value The audioContent to set.
       * @return This builder for chaining.
       */
      public Builder setAudioContent(com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        streamingRequestCase_ = 2;
        streamingRequest_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>bytes audio_content = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioContent() {
        if (streamingRequestCase_ == 2) {
          streamingRequestCase_ = 0;
          streamingRequest_ = null;
          onChanged();
        }
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognizeRequest)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognizeRequest)
    private static final StreamingRecognizeRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new StreamingRecognizeRequest();
    }

    public static StreamingRecognizeRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognizeRequest>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognizeRequest>() {
      @Override
      public StreamingRecognizeRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognizeRequest> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingRecognizeRequest> getParserForType() {
      return PARSER;
    }

    @Override
    public StreamingRecognizeRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecognitionConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognitionConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     *
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
     * @return The enum numeric value on the wire for encoding.
     */
    int getEncodingValue();
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     *
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
     * @return The encoding.
     */
    RivaAudio.AudioEncoding getEncoding();

    /**
     * <pre>
     *  The sample rate in hertz (Hz) of the audio data sent in the
     * `RecognizeRequest` or `StreamingRecognizeRequest` messages.
     *  The Riva server will automatically down-sample/up-sample the audio to match the ASR acoustic model sample rate.
     *  The sample rate value below 8kHz will not produce any meaningful output.
     * </pre>
     *
     * <code>int32 sample_rate_hertz = 2;</code>
     * @return The sampleRateHertz.
     */
    int getSampleRateHertz();

    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>string language_code = 3;</code>
     * @return The languageCode.
     */
    String getLanguageCode();
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>string language_code = 3;</code>
     * @return The bytes for languageCode.
     */
    com.google.protobuf.ByteString
        getLanguageCodeBytes();

    /**
     * <pre>
     * Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
     * within each `SpeechRecognizeResult`.
     * The server may return fewer than `max_alternatives`.
     * If omitted, will return a maximum of one.
     * </pre>
     *
     * <code>int32 max_alternatives = 4;</code>
     * @return The maxAlternatives.
     */
    int getMaxAlternatives();

    /**
     * <pre>
     * A custom field that enables profanity filtering for the generated transcripts. 
     * If set to 'true', the server filters out profanities, replacing all but the initial
     * character in each filtered word with asterisks. For example, "h***". 
     * If set to `false` or omitted, profanities will not be filtered out. The default is `false`.
     * </pre>
     *
     * <code>bool profanity_filter = 5;</code>
     * @return The profanityFilter.
     */
    boolean getProfanityFilter();

    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    java.util.List<SpeechContext>
        getSpeechContextsList();
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    SpeechContext getSpeechContexts(int index);
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    int getSpeechContextsCount();
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    java.util.List<? extends SpeechContextOrBuilder>
        getSpeechContextsOrBuilderList();
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    SpeechContextOrBuilder getSpeechContextsOrBuilder(
        int index);

    /**
     * <pre>
     * The number of channels in the input audio data.
     * ONLY set this for MULTI-CHANNEL recognition.
     * Valid values for LINEAR16 and FLAC are `1`-`8`.
     * Valid values for OGG_OPUS are '1'-'254'.
     * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
     * If `0` or omitted, defaults to one channel (mono).
     * Note: We only recognize the first channel by default.
     * To perform independent recognition on each channel set
     * `enable_separate_recognition_per_channel` to 'true'.
     * </pre>
     *
     * <code>int32 audio_channel_count = 7;</code>
     * @return The audioChannelCount.
     */
    int getAudioChannelCount();

    /**
     * <pre>
     * If `true`, the top result includes a list of words and
     * the start and end time offsets (timestamps) for those words. If
     * `false`, no word-level time offset information is returned. The default is
     * `false`.
     * </pre>
     *
     * <code>bool enable_word_time_offsets = 8;</code>
     * @return The enableWordTimeOffsets.
     */
    boolean getEnableWordTimeOffsets();

    /**
     * <pre>
     * If 'true', adds punctuation to recognition result hypotheses.
     * The default 'false' value does not add punctuation to result hypotheses.
     * </pre>
     *
     * <code>bool enable_automatic_punctuation = 11;</code>
     * @return The enableAutomaticPunctuation.
     */
    boolean getEnableAutomaticPunctuation();

    /**
     * <pre>
     * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
     * to get each channel recognized separately. The recognition result will
     * contain a `channel_tag` field to state which channel that result belongs
     * to. If this is not true, we will only recognize the first channel. The
     * request is billed cumulatively for all channels recognized:
     * `audio_channel_count` multiplied by the length of the audio.
     * </pre>
     *
     * <code>bool enable_separate_recognition_per_channel = 12;</code>
     * @return The enableSeparateRecognitionPerChannel.
     */
    boolean getEnableSeparateRecognitionPerChannel();

    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>string model = 13;</code>
     * @return The model.
     */
    String getModel();
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>string model = 13;</code>
     * @return The bytes for model.
     */
    com.google.protobuf.ByteString
        getModelBytes();

    /**
     * <pre>
     * The verbatim_transcripts flag enables or disable inverse text normalization.
     * 'true' returns exactly what was said, with no denormalization.
     * 'false' applies inverse text normalization, also this is the default
     * </pre>
     *
     * <code>bool verbatim_transcripts = 14;</code>
     * @return The verbatimTranscripts.
     */
    boolean getVerbatimTranscripts();

    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    int getCustomConfigurationCount();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    boolean containsCustomConfiguration(
        String key);
    /**
     * Use {@link #getCustomConfigurationMap()} instead.
     */
    @Deprecated
    java.util.Map<String, String>
    getCustomConfiguration();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    java.util.Map<String, String>
    getCustomConfigurationMap();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    /* nullable */
String getCustomConfigurationOrDefault(
        String key,
        /* nullable */
String defaultValue);
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    String getCustomConfigurationOrThrow(
        String key);
  }
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the request
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognitionConfig}
   */
  public static final class RecognitionConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognitionConfig)
      RecognitionConfigOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecognitionConfig.newBuilder() to construct.
    private RecognitionConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognitionConfig() {
      encoding_ = 0;
      languageCode_ = "";
      speechContexts_ = java.util.Collections.emptyList();
      model_ = "";
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new RecognitionConfig();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 24:
          return internalGetCustomConfiguration();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              RecognitionConfig.class, Builder.class);
    }

    public static final int ENCODING_FIELD_NUMBER = 1;
    private int encoding_ = 0;
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     *
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
     * @return The enum numeric value on the wire for encoding.
     */
    @Override public int getEncodingValue() {
      return encoding_;
    }
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     *
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
     * @return The encoding.
     */
    @Override public RivaAudio.AudioEncoding getEncoding() {
      RivaAudio.AudioEncoding result = RivaAudio.AudioEncoding.forNumber(encoding_);
      return result == null ? RivaAudio.AudioEncoding.UNRECOGNIZED : result;
    }

    public static final int SAMPLE_RATE_HERTZ_FIELD_NUMBER = 2;
    private int sampleRateHertz_ = 0;
    /**
     * <pre>
     *  The sample rate in hertz (Hz) of the audio data sent in the
     * `RecognizeRequest` or `StreamingRecognizeRequest` messages.
     *  The Riva server will automatically down-sample/up-sample the audio to match the ASR acoustic model sample rate.
     *  The sample rate value below 8kHz will not produce any meaningful output.
     * </pre>
     *
     * <code>int32 sample_rate_hertz = 2;</code>
     * @return The sampleRateHertz.
     */
    @Override
    public int getSampleRateHertz() {
      return sampleRateHertz_;
    }

    public static final int LANGUAGE_CODE_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile Object languageCode_ = "";
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>string language_code = 3;</code>
     * @return The languageCode.
     */
    @Override
    public String getLanguageCode() {
      Object ref = languageCode_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        languageCode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>string language_code = 3;</code>
     * @return The bytes for languageCode.
     */
    @Override
    public com.google.protobuf.ByteString
        getLanguageCodeBytes() {
      Object ref = languageCode_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        languageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int MAX_ALTERNATIVES_FIELD_NUMBER = 4;
    private int maxAlternatives_ = 0;
    /**
     * <pre>
     * Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
     * within each `SpeechRecognizeResult`.
     * The server may return fewer than `max_alternatives`.
     * If omitted, will return a maximum of one.
     * </pre>
     *
     * <code>int32 max_alternatives = 4;</code>
     * @return The maxAlternatives.
     */
    @Override
    public int getMaxAlternatives() {
      return maxAlternatives_;
    }

    public static final int PROFANITY_FILTER_FIELD_NUMBER = 5;
    private boolean profanityFilter_ = false;
    /**
     * <pre>
     * A custom field that enables profanity filtering for the generated transcripts. 
     * If set to 'true', the server filters out profanities, replacing all but the initial
     * character in each filtered word with asterisks. For example, "h***". 
     * If set to `false` or omitted, profanities will not be filtered out. The default is `false`.
     * </pre>
     *
     * <code>bool profanity_filter = 5;</code>
     * @return The profanityFilter.
     */
    @Override
    public boolean getProfanityFilter() {
      return profanityFilter_;
    }

    public static final int SPEECH_CONTEXTS_FIELD_NUMBER = 6;
    @SuppressWarnings("serial")
    private java.util.List<SpeechContext> speechContexts_;
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    @Override
    public java.util.List<SpeechContext> getSpeechContextsList() {
      return speechContexts_;
    }
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    @Override
    public java.util.List<? extends SpeechContextOrBuilder>
        getSpeechContextsOrBuilderList() {
      return speechContexts_;
    }
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    @Override
    public int getSpeechContextsCount() {
      return speechContexts_.size();
    }
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    @Override
    public SpeechContext getSpeechContexts(int index) {
      return speechContexts_.get(index);
    }
    /**
     * <pre>
     * Array of SpeechContext.
     * A means to provide context to assist the speech recognition. For more
     * information, see SpeechContext section
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
     */
    @Override
    public SpeechContextOrBuilder getSpeechContextsOrBuilder(
        int index) {
      return speechContexts_.get(index);
    }

    public static final int AUDIO_CHANNEL_COUNT_FIELD_NUMBER = 7;
    private int audioChannelCount_ = 0;
    /**
     * <pre>
     * The number of channels in the input audio data.
     * ONLY set this for MULTI-CHANNEL recognition.
     * Valid values for LINEAR16 and FLAC are `1`-`8`.
     * Valid values for OGG_OPUS are '1'-'254'.
     * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
     * If `0` or omitted, defaults to one channel (mono).
     * Note: We only recognize the first channel by default.
     * To perform independent recognition on each channel set
     * `enable_separate_recognition_per_channel` to 'true'.
     * </pre>
     *
     * <code>int32 audio_channel_count = 7;</code>
     * @return The audioChannelCount.
     */
    @Override
    public int getAudioChannelCount() {
      return audioChannelCount_;
    }

    public static final int ENABLE_WORD_TIME_OFFSETS_FIELD_NUMBER = 8;
    private boolean enableWordTimeOffsets_ = false;
    /**
     * <pre>
     * If `true`, the top result includes a list of words and
     * the start and end time offsets (timestamps) for those words. If
     * `false`, no word-level time offset information is returned. The default is
     * `false`.
     * </pre>
     *
     * <code>bool enable_word_time_offsets = 8;</code>
     * @return The enableWordTimeOffsets.
     */
    @Override
    public boolean getEnableWordTimeOffsets() {
      return enableWordTimeOffsets_;
    }

    public static final int ENABLE_AUTOMATIC_PUNCTUATION_FIELD_NUMBER = 11;
    private boolean enableAutomaticPunctuation_ = false;
    /**
     * <pre>
     * If 'true', adds punctuation to recognition result hypotheses.
     * The default 'false' value does not add punctuation to result hypotheses.
     * </pre>
     *
     * <code>bool enable_automatic_punctuation = 11;</code>
     * @return The enableAutomaticPunctuation.
     */
    @Override
    public boolean getEnableAutomaticPunctuation() {
      return enableAutomaticPunctuation_;
    }

    public static final int ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL_FIELD_NUMBER = 12;
    private boolean enableSeparateRecognitionPerChannel_ = false;
    /**
     * <pre>
     * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
     * to get each channel recognized separately. The recognition result will
     * contain a `channel_tag` field to state which channel that result belongs
     * to. If this is not true, we will only recognize the first channel. The
     * request is billed cumulatively for all channels recognized:
     * `audio_channel_count` multiplied by the length of the audio.
     * </pre>
     *
     * <code>bool enable_separate_recognition_per_channel = 12;</code>
     * @return The enableSeparateRecognitionPerChannel.
     */
    @Override
    public boolean getEnableSeparateRecognitionPerChannel() {
      return enableSeparateRecognitionPerChannel_;
    }

    public static final int MODEL_FIELD_NUMBER = 13;
    @SuppressWarnings("serial")
    private volatile Object model_ = "";
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>string model = 13;</code>
     * @return The model.
     */
    @Override
    public String getModel() {
      Object ref = model_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        model_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>string model = 13;</code>
     * @return The bytes for model.
     */
    @Override
    public com.google.protobuf.ByteString
        getModelBytes() {
      Object ref = model_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        model_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VERBATIM_TRANSCRIPTS_FIELD_NUMBER = 14;
    private boolean verbatimTranscripts_ = false;
    /**
     * <pre>
     * The verbatim_transcripts flag enables or disable inverse text normalization.
     * 'true' returns exactly what was said, with no denormalization.
     * 'false' applies inverse text normalization, also this is the default
     * </pre>
     *
     * <code>bool verbatim_transcripts = 14;</code>
     * @return The verbatimTranscripts.
     */
    @Override
    public boolean getVerbatimTranscripts() {
      return verbatimTranscripts_;
    }

    public static final int CUSTOM_CONFIGURATION_FIELD_NUMBER = 24;
    private static final class CustomConfigurationDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          String, String> defaultEntry =
              com.google.protobuf.MapEntry
              .<String, String>newDefaultInstance(
                  RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    @SuppressWarnings("serial")
    private com.google.protobuf.MapField<
        String, String> customConfiguration_;
    private com.google.protobuf.MapField<String, String>
    internalGetCustomConfiguration() {
      if (customConfiguration_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            CustomConfigurationDefaultEntryHolder.defaultEntry);
      }
      return customConfiguration_;
    }
    public int getCustomConfigurationCount() {
      return internalGetCustomConfiguration().getMap().size();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    @Override
    public boolean containsCustomConfiguration(
        String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetCustomConfiguration().getMap().containsKey(key);
    }
    /**
     * Use {@link #getCustomConfigurationMap()} instead.
     */
    @Override
    @Deprecated
    public java.util.Map<String, String> getCustomConfiguration() {
      return getCustomConfigurationMap();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    @Override
    public java.util.Map<String, String> getCustomConfigurationMap() {
      return internalGetCustomConfiguration().getMap();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    @Override
    public /* nullable */
String getCustomConfigurationOrDefault(
        String key,
        /* nullable */
String defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<String, String> map =
          internalGetCustomConfiguration().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    @Override
    public String getCustomConfigurationOrThrow(
        String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<String, String> map =
          internalGetCustomConfiguration().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (encoding_ != RivaAudio.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, encoding_);
      }
      if (sampleRateHertz_ != 0) {
        output.writeInt32(2, sampleRateHertz_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(languageCode_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, languageCode_);
      }
      if (maxAlternatives_ != 0) {
        output.writeInt32(4, maxAlternatives_);
      }
      if (profanityFilter_ != false) {
        output.writeBool(5, profanityFilter_);
      }
      for (int i = 0; i < speechContexts_.size(); i++) {
        output.writeMessage(6, speechContexts_.get(i));
      }
      if (audioChannelCount_ != 0) {
        output.writeInt32(7, audioChannelCount_);
      }
      if (enableWordTimeOffsets_ != false) {
        output.writeBool(8, enableWordTimeOffsets_);
      }
      if (enableAutomaticPunctuation_ != false) {
        output.writeBool(11, enableAutomaticPunctuation_);
      }
      if (enableSeparateRecognitionPerChannel_ != false) {
        output.writeBool(12, enableSeparateRecognitionPerChannel_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(model_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 13, model_);
      }
      if (verbatimTranscripts_ != false) {
        output.writeBool(14, verbatimTranscripts_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetCustomConfiguration(),
          CustomConfigurationDefaultEntryHolder.defaultEntry,
          24);
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (encoding_ != RivaAudio.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, encoding_);
      }
      if (sampleRateHertz_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, sampleRateHertz_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(languageCode_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, languageCode_);
      }
      if (maxAlternatives_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, maxAlternatives_);
      }
      if (profanityFilter_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, profanityFilter_);
      }
      for (int i = 0; i < speechContexts_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, speechContexts_.get(i));
      }
      if (audioChannelCount_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(7, audioChannelCount_);
      }
      if (enableWordTimeOffsets_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, enableWordTimeOffsets_);
      }
      if (enableAutomaticPunctuation_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, enableAutomaticPunctuation_);
      }
      if (enableSeparateRecognitionPerChannel_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(12, enableSeparateRecognitionPerChannel_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(model_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(13, model_);
      }
      if (verbatimTranscripts_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(14, verbatimTranscripts_);
      }
      for (java.util.Map.Entry<String, String> entry
           : internalGetCustomConfiguration().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, String>
        customConfiguration__ = CustomConfigurationDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(24, customConfiguration__);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof RecognitionConfig)) {
        return super.equals(obj);
      }
      RecognitionConfig other = (RecognitionConfig) obj;

      if (encoding_ != other.encoding_) return false;
      if (getSampleRateHertz()
          != other.getSampleRateHertz()) return false;
      if (!getLanguageCode()
          .equals(other.getLanguageCode())) return false;
      if (getMaxAlternatives()
          != other.getMaxAlternatives()) return false;
      if (getProfanityFilter()
          != other.getProfanityFilter()) return false;
      if (!getSpeechContextsList()
          .equals(other.getSpeechContextsList())) return false;
      if (getAudioChannelCount()
          != other.getAudioChannelCount()) return false;
      if (getEnableWordTimeOffsets()
          != other.getEnableWordTimeOffsets()) return false;
      if (getEnableAutomaticPunctuation()
          != other.getEnableAutomaticPunctuation()) return false;
      if (getEnableSeparateRecognitionPerChannel()
          != other.getEnableSeparateRecognitionPerChannel()) return false;
      if (!getModel()
          .equals(other.getModel())) return false;
      if (getVerbatimTranscripts()
          != other.getVerbatimTranscripts()) return false;
      if (!internalGetCustomConfiguration().equals(
          other.internalGetCustomConfiguration())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + ENCODING_FIELD_NUMBER;
      hash = (53 * hash) + encoding_;
      hash = (37 * hash) + SAMPLE_RATE_HERTZ_FIELD_NUMBER;
      hash = (53 * hash) + getSampleRateHertz();
      hash = (37 * hash) + LANGUAGE_CODE_FIELD_NUMBER;
      hash = (53 * hash) + getLanguageCode().hashCode();
      hash = (37 * hash) + MAX_ALTERNATIVES_FIELD_NUMBER;
      hash = (53 * hash) + getMaxAlternatives();
      hash = (37 * hash) + PROFANITY_FILTER_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getProfanityFilter());
      if (getSpeechContextsCount() > 0) {
        hash = (37 * hash) + SPEECH_CONTEXTS_FIELD_NUMBER;
        hash = (53 * hash) + getSpeechContextsList().hashCode();
      }
      hash = (37 * hash) + AUDIO_CHANNEL_COUNT_FIELD_NUMBER;
      hash = (53 * hash) + getAudioChannelCount();
      hash = (37 * hash) + ENABLE_WORD_TIME_OFFSETS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableWordTimeOffsets());
      hash = (37 * hash) + ENABLE_AUTOMATIC_PUNCTUATION_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableAutomaticPunctuation());
      hash = (37 * hash) + ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableSeparateRecognitionPerChannel());
      hash = (37 * hash) + MODEL_FIELD_NUMBER;
      hash = (53 * hash) + getModel().hashCode();
      hash = (37 * hash) + VERBATIM_TRANSCRIPTS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getVerbatimTranscripts());
      if (!internalGetCustomConfiguration().getMap().isEmpty()) {
        hash = (37 * hash) + CUSTOM_CONFIGURATION_FIELD_NUMBER;
        hash = (53 * hash) + internalGetCustomConfiguration().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static RecognitionConfig parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognitionConfig parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognitionConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognitionConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognitionConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognitionConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognitionConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognitionConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static RecognitionConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static RecognitionConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static RecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(RecognitionConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognitionConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognitionConfig)
        RecognitionConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 24:
            return internalGetCustomConfiguration();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 24:
            return internalGetMutableCustomConfiguration();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                RecognitionConfig.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.RecognitionConfig.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        encoding_ = 0;
        sampleRateHertz_ = 0;
        languageCode_ = "";
        maxAlternatives_ = 0;
        profanityFilter_ = false;
        if (speechContextsBuilder_ == null) {
          speechContexts_ = java.util.Collections.emptyList();
        } else {
          speechContexts_ = null;
          speechContextsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        audioChannelCount_ = 0;
        enableWordTimeOffsets_ = false;
        enableAutomaticPunctuation_ = false;
        enableSeparateRecognitionPerChannel_ = false;
        model_ = "";
        verbatimTranscripts_ = false;
        internalGetMutableCustomConfiguration().clear();
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
      }

      @Override
      public RecognitionConfig getDefaultInstanceForType() {
        return RecognitionConfig.getDefaultInstance();
      }

      @Override
      public RecognitionConfig build() {
        RecognitionConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public RecognitionConfig buildPartial() {
        RecognitionConfig result = new RecognitionConfig(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(RecognitionConfig result) {
        if (speechContextsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) != 0)) {
            speechContexts_ = java.util.Collections.unmodifiableList(speechContexts_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.speechContexts_ = speechContexts_;
        } else {
          result.speechContexts_ = speechContextsBuilder_.build();
        }
      }

      private void buildPartial0(RecognitionConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.encoding_ = encoding_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.sampleRateHertz_ = sampleRateHertz_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.languageCode_ = languageCode_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.maxAlternatives_ = maxAlternatives_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.profanityFilter_ = profanityFilter_;
        }
        if (((from_bitField0_ & 0x00000040) != 0)) {
          result.audioChannelCount_ = audioChannelCount_;
        }
        if (((from_bitField0_ & 0x00000080) != 0)) {
          result.enableWordTimeOffsets_ = enableWordTimeOffsets_;
        }
        if (((from_bitField0_ & 0x00000100) != 0)) {
          result.enableAutomaticPunctuation_ = enableAutomaticPunctuation_;
        }
        if (((from_bitField0_ & 0x00000200) != 0)) {
          result.enableSeparateRecognitionPerChannel_ = enableSeparateRecognitionPerChannel_;
        }
        if (((from_bitField0_ & 0x00000400) != 0)) {
          result.model_ = model_;
        }
        if (((from_bitField0_ & 0x00000800) != 0)) {
          result.verbatimTranscripts_ = verbatimTranscripts_;
        }
        if (((from_bitField0_ & 0x00001000) != 0)) {
          result.customConfiguration_ = internalGetCustomConfiguration();
          result.customConfiguration_.makeImmutable();
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof RecognitionConfig) {
          return mergeFrom((RecognitionConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(RecognitionConfig other) {
        if (other == RecognitionConfig.getDefaultInstance()) return this;
        if (other.encoding_ != 0) {
          setEncodingValue(other.getEncodingValue());
        }
        if (other.getSampleRateHertz() != 0) {
          setSampleRateHertz(other.getSampleRateHertz());
        }
        if (!other.getLanguageCode().isEmpty()) {
          languageCode_ = other.languageCode_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.getMaxAlternatives() != 0) {
          setMaxAlternatives(other.getMaxAlternatives());
        }
        if (other.getProfanityFilter() != false) {
          setProfanityFilter(other.getProfanityFilter());
        }
        if (speechContextsBuilder_ == null) {
          if (!other.speechContexts_.isEmpty()) {
            if (speechContexts_.isEmpty()) {
              speechContexts_ = other.speechContexts_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureSpeechContextsIsMutable();
              speechContexts_.addAll(other.speechContexts_);
            }
            onChanged();
          }
        } else {
          if (!other.speechContexts_.isEmpty()) {
            if (speechContextsBuilder_.isEmpty()) {
              speechContextsBuilder_.dispose();
              speechContextsBuilder_ = null;
              speechContexts_ = other.speechContexts_;
              bitField0_ = (bitField0_ & ~0x00000020);
              speechContextsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getSpeechContextsFieldBuilder() : null;
            } else {
              speechContextsBuilder_.addAllMessages(other.speechContexts_);
            }
          }
        }
        if (other.getAudioChannelCount() != 0) {
          setAudioChannelCount(other.getAudioChannelCount());
        }
        if (other.getEnableWordTimeOffsets() != false) {
          setEnableWordTimeOffsets(other.getEnableWordTimeOffsets());
        }
        if (other.getEnableAutomaticPunctuation() != false) {
          setEnableAutomaticPunctuation(other.getEnableAutomaticPunctuation());
        }
        if (other.getEnableSeparateRecognitionPerChannel() != false) {
          setEnableSeparateRecognitionPerChannel(other.getEnableSeparateRecognitionPerChannel());
        }
        if (!other.getModel().isEmpty()) {
          model_ = other.model_;
          bitField0_ |= 0x00000400;
          onChanged();
        }
        if (other.getVerbatimTranscripts() != false) {
          setVerbatimTranscripts(other.getVerbatimTranscripts());
        }
        internalGetMutableCustomConfiguration().mergeFrom(
            other.internalGetCustomConfiguration());
        bitField0_ |= 0x00001000;
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                encoding_ = input.readEnum();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                sampleRateHertz_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                languageCode_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 32: {
                maxAlternatives_ = input.readInt32();
                bitField0_ |= 0x00000008;
                break;
              } // case 32
              case 40: {
                profanityFilter_ = input.readBool();
                bitField0_ |= 0x00000010;
                break;
              } // case 40
              case 50: {
                SpeechContext m =
                    input.readMessage(
                        SpeechContext.parser(),
                        extensionRegistry);
                if (speechContextsBuilder_ == null) {
                  ensureSpeechContextsIsMutable();
                  speechContexts_.add(m);
                } else {
                  speechContextsBuilder_.addMessage(m);
                }
                break;
              } // case 50
              case 56: {
                audioChannelCount_ = input.readInt32();
                bitField0_ |= 0x00000040;
                break;
              } // case 56
              case 64: {
                enableWordTimeOffsets_ = input.readBool();
                bitField0_ |= 0x00000080;
                break;
              } // case 64
              case 88: {
                enableAutomaticPunctuation_ = input.readBool();
                bitField0_ |= 0x00000100;
                break;
              } // case 88
              case 96: {
                enableSeparateRecognitionPerChannel_ = input.readBool();
                bitField0_ |= 0x00000200;
                break;
              } // case 96
              case 106: {
                model_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000400;
                break;
              } // case 106
              case 112: {
                verbatimTranscripts_ = input.readBool();
                bitField0_ |= 0x00000800;
                break;
              } // case 112
              case 194: {
                com.google.protobuf.MapEntry<String, String>
                customConfiguration__ = input.readMessage(
                    CustomConfigurationDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
                internalGetMutableCustomConfiguration().getMutableMap().put(
                    customConfiguration__.getKey(), customConfiguration__.getValue());
                bitField0_ |= 0x00001000;
                break;
              } // case 194
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int encoding_ = 0;
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       *
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
       * @return The enum numeric value on the wire for encoding.
       */
      @Override public int getEncodingValue() {
        return encoding_;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       *
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
       * @param value The enum numeric value on the wire for encoding to set.
       * @return This builder for chaining.
       */
      public Builder setEncodingValue(int value) {
        encoding_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       *
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
       * @return The encoding.
       */
      @Override
      public RivaAudio.AudioEncoding getEncoding() {
        RivaAudio.AudioEncoding result = RivaAudio.AudioEncoding.forNumber(encoding_);
        return result == null ? RivaAudio.AudioEncoding.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       *
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
       * @param value The encoding to set.
       * @return This builder for chaining.
       */
      public Builder setEncoding(RivaAudio.AudioEncoding value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        encoding_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       *
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>.nvidia.riva.AudioEncoding encoding = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearEncoding() {
        bitField0_ = (bitField0_ & ~0x00000001);
        encoding_ = 0;
        onChanged();
        return this;
      }

      private int sampleRateHertz_ ;
      /**
       * <pre>
       *  The sample rate in hertz (Hz) of the audio data sent in the
       * `RecognizeRequest` or `StreamingRecognizeRequest` messages.
       *  The Riva server will automatically down-sample/up-sample the audio to match the ASR acoustic model sample rate.
       *  The sample rate value below 8kHz will not produce any meaningful output.
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 2;</code>
       * @return The sampleRateHertz.
       */
      @Override
      public int getSampleRateHertz() {
        return sampleRateHertz_;
      }
      /**
       * <pre>
       *  The sample rate in hertz (Hz) of the audio data sent in the
       * `RecognizeRequest` or `StreamingRecognizeRequest` messages.
       *  The Riva server will automatically down-sample/up-sample the audio to match the ASR acoustic model sample rate.
       *  The sample rate value below 8kHz will not produce any meaningful output.
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 2;</code>
       * @param value The sampleRateHertz to set.
       * @return This builder for chaining.
       */
      public Builder setSampleRateHertz(int value) {

        sampleRateHertz_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *  The sample rate in hertz (Hz) of the audio data sent in the
       * `RecognizeRequest` or `StreamingRecognizeRequest` messages.
       *  The Riva server will automatically down-sample/up-sample the audio to match the ASR acoustic model sample rate.
       *  The sample rate value below 8kHz will not produce any meaningful output.
       * </pre>
       *
       * <code>int32 sample_rate_hertz = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearSampleRateHertz() {
        bitField0_ = (bitField0_ & ~0x00000002);
        sampleRateHertz_ = 0;
        onChanged();
        return this;
      }

      private Object languageCode_ = "";
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>string language_code = 3;</code>
       * @return The languageCode.
       */
      public String getLanguageCode() {
        Object ref = languageCode_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          languageCode_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>string language_code = 3;</code>
       * @return The bytes for languageCode.
       */
      public com.google.protobuf.ByteString
          getLanguageCodeBytes() {
        Object ref = languageCode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          languageCode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>string language_code = 3;</code>
       * @param value The languageCode to set.
       * @return This builder for chaining.
       */
      public Builder setLanguageCode(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        languageCode_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>string language_code = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearLanguageCode() {
        languageCode_ = getDefaultInstance().getLanguageCode();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>string language_code = 3;</code>
       * @param value The bytes for languageCode to set.
       * @return This builder for chaining.
       */
      public Builder setLanguageCodeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        languageCode_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private int maxAlternatives_ ;
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>int32 max_alternatives = 4;</code>
       * @return The maxAlternatives.
       */
      @Override
      public int getMaxAlternatives() {
        return maxAlternatives_;
      }
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>int32 max_alternatives = 4;</code>
       * @param value The maxAlternatives to set.
       * @return This builder for chaining.
       */
      public Builder setMaxAlternatives(int value) {

        maxAlternatives_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>int32 max_alternatives = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearMaxAlternatives() {
        bitField0_ = (bitField0_ & ~0x00000008);
        maxAlternatives_ = 0;
        onChanged();
        return this;
      }

      private boolean profanityFilter_ ;
      /**
       * <pre>
       * A custom field that enables profanity filtering for the generated transcripts. 
       * If set to 'true', the server filters out profanities, replacing all but the initial
       * character in each filtered word with asterisks. For example, "h***". 
       * If set to `false` or omitted, profanities will not be filtered out. The default is `false`.
       * </pre>
       *
       * <code>bool profanity_filter = 5;</code>
       * @return The profanityFilter.
       */
      @Override
      public boolean getProfanityFilter() {
        return profanityFilter_;
      }
      /**
       * <pre>
       * A custom field that enables profanity filtering for the generated transcripts. 
       * If set to 'true', the server filters out profanities, replacing all but the initial
       * character in each filtered word with asterisks. For example, "h***". 
       * If set to `false` or omitted, profanities will not be filtered out. The default is `false`.
       * </pre>
       *
       * <code>bool profanity_filter = 5;</code>
       * @param value The profanityFilter to set.
       * @return This builder for chaining.
       */
      public Builder setProfanityFilter(boolean value) {

        profanityFilter_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A custom field that enables profanity filtering for the generated transcripts. 
       * If set to 'true', the server filters out profanities, replacing all but the initial
       * character in each filtered word with asterisks. For example, "h***". 
       * If set to `false` or omitted, profanities will not be filtered out. The default is `false`.
       * </pre>
       *
       * <code>bool profanity_filter = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearProfanityFilter() {
        bitField0_ = (bitField0_ & ~0x00000010);
        profanityFilter_ = false;
        onChanged();
        return this;
      }

      private java.util.List<SpeechContext> speechContexts_ =
        java.util.Collections.emptyList();
      private void ensureSpeechContextsIsMutable() {
        if (!((bitField0_ & 0x00000020) != 0)) {
          speechContexts_ = new java.util.ArrayList<SpeechContext>(speechContexts_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechContext, SpeechContext.Builder, SpeechContextOrBuilder> speechContextsBuilder_;

      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public java.util.List<SpeechContext> getSpeechContextsList() {
        if (speechContextsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(speechContexts_);
        } else {
          return speechContextsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public int getSpeechContextsCount() {
        if (speechContextsBuilder_ == null) {
          return speechContexts_.size();
        } else {
          return speechContextsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public SpeechContext getSpeechContexts(int index) {
        if (speechContextsBuilder_ == null) {
          return speechContexts_.get(index);
        } else {
          return speechContextsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder setSpeechContexts(
          int index, SpeechContext value) {
        if (speechContextsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSpeechContextsIsMutable();
          speechContexts_.set(index, value);
          onChanged();
        } else {
          speechContextsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder setSpeechContexts(
          int index, SpeechContext.Builder builderForValue) {
        if (speechContextsBuilder_ == null) {
          ensureSpeechContextsIsMutable();
          speechContexts_.set(index, builderForValue.build());
          onChanged();
        } else {
          speechContextsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder addSpeechContexts(SpeechContext value) {
        if (speechContextsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSpeechContextsIsMutable();
          speechContexts_.add(value);
          onChanged();
        } else {
          speechContextsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder addSpeechContexts(
          int index, SpeechContext value) {
        if (speechContextsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSpeechContextsIsMutable();
          speechContexts_.add(index, value);
          onChanged();
        } else {
          speechContextsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder addSpeechContexts(
          SpeechContext.Builder builderForValue) {
        if (speechContextsBuilder_ == null) {
          ensureSpeechContextsIsMutable();
          speechContexts_.add(builderForValue.build());
          onChanged();
        } else {
          speechContextsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder addSpeechContexts(
          int index, SpeechContext.Builder builderForValue) {
        if (speechContextsBuilder_ == null) {
          ensureSpeechContextsIsMutable();
          speechContexts_.add(index, builderForValue.build());
          onChanged();
        } else {
          speechContextsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder addAllSpeechContexts(
          Iterable<? extends SpeechContext> values) {
        if (speechContextsBuilder_ == null) {
          ensureSpeechContextsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, speechContexts_);
          onChanged();
        } else {
          speechContextsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder clearSpeechContexts() {
        if (speechContextsBuilder_ == null) {
          speechContexts_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          speechContextsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public Builder removeSpeechContexts(int index) {
        if (speechContextsBuilder_ == null) {
          ensureSpeechContextsIsMutable();
          speechContexts_.remove(index);
          onChanged();
        } else {
          speechContextsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public SpeechContext.Builder getSpeechContextsBuilder(
          int index) {
        return getSpeechContextsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public SpeechContextOrBuilder getSpeechContextsOrBuilder(
          int index) {
        if (speechContextsBuilder_ == null) {
          return speechContexts_.get(index);  } else {
          return speechContextsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public java.util.List<? extends SpeechContextOrBuilder>
           getSpeechContextsOrBuilderList() {
        if (speechContextsBuilder_ != null) {
          return speechContextsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(speechContexts_);
        }
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public SpeechContext.Builder addSpeechContextsBuilder() {
        return getSpeechContextsFieldBuilder().addBuilder(
            SpeechContext.getDefaultInstance());
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public SpeechContext.Builder addSpeechContextsBuilder(
          int index) {
        return getSpeechContextsFieldBuilder().addBuilder(
            index, SpeechContext.getDefaultInstance());
      }
      /**
       * <pre>
       * Array of SpeechContext.
       * A means to provide context to assist the speech recognition. For more
       * information, see SpeechContext section
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechContext speech_contexts = 6;</code>
       */
      public java.util.List<SpeechContext.Builder>
           getSpeechContextsBuilderList() {
        return getSpeechContextsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechContext, SpeechContext.Builder, SpeechContextOrBuilder>
          getSpeechContextsFieldBuilder() {
        if (speechContextsBuilder_ == null) {
          speechContextsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              SpeechContext, SpeechContext.Builder, SpeechContextOrBuilder>(
                  speechContexts_,
                  ((bitField0_ & 0x00000020) != 0),
                  getParentForChildren(),
                  isClean());
          speechContexts_ = null;
        }
        return speechContextsBuilder_;
      }

      private int audioChannelCount_ ;
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>int32 audio_channel_count = 7;</code>
       * @return The audioChannelCount.
       */
      @Override
      public int getAudioChannelCount() {
        return audioChannelCount_;
      }
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>int32 audio_channel_count = 7;</code>
       * @param value The audioChannelCount to set.
       * @return This builder for chaining.
       */
      public Builder setAudioChannelCount(int value) {

        audioChannelCount_ = value;
        bitField0_ |= 0x00000040;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>int32 audio_channel_count = 7;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioChannelCount() {
        bitField0_ = (bitField0_ & ~0x00000040);
        audioChannelCount_ = 0;
        onChanged();
        return this;
      }

      private boolean enableWordTimeOffsets_ ;
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>bool enable_word_time_offsets = 8;</code>
       * @return The enableWordTimeOffsets.
       */
      @Override
      public boolean getEnableWordTimeOffsets() {
        return enableWordTimeOffsets_;
      }
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>bool enable_word_time_offsets = 8;</code>
       * @param value The enableWordTimeOffsets to set.
       * @return This builder for chaining.
       */
      public Builder setEnableWordTimeOffsets(boolean value) {

        enableWordTimeOffsets_ = value;
        bitField0_ |= 0x00000080;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>bool enable_word_time_offsets = 8;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnableWordTimeOffsets() {
        bitField0_ = (bitField0_ & ~0x00000080);
        enableWordTimeOffsets_ = false;
        onChanged();
        return this;
      }

      private boolean enableAutomaticPunctuation_ ;
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>bool enable_automatic_punctuation = 11;</code>
       * @return The enableAutomaticPunctuation.
       */
      @Override
      public boolean getEnableAutomaticPunctuation() {
        return enableAutomaticPunctuation_;
      }
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>bool enable_automatic_punctuation = 11;</code>
       * @param value The enableAutomaticPunctuation to set.
       * @return This builder for chaining.
       */
      public Builder setEnableAutomaticPunctuation(boolean value) {

        enableAutomaticPunctuation_ = value;
        bitField0_ |= 0x00000100;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>bool enable_automatic_punctuation = 11;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnableAutomaticPunctuation() {
        bitField0_ = (bitField0_ & ~0x00000100);
        enableAutomaticPunctuation_ = false;
        onChanged();
        return this;
      }

      private boolean enableSeparateRecognitionPerChannel_ ;
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>bool enable_separate_recognition_per_channel = 12;</code>
       * @return The enableSeparateRecognitionPerChannel.
       */
      @Override
      public boolean getEnableSeparateRecognitionPerChannel() {
        return enableSeparateRecognitionPerChannel_;
      }
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>bool enable_separate_recognition_per_channel = 12;</code>
       * @param value The enableSeparateRecognitionPerChannel to set.
       * @return This builder for chaining.
       */
      public Builder setEnableSeparateRecognitionPerChannel(boolean value) {

        enableSeparateRecognitionPerChannel_ = value;
        bitField0_ |= 0x00000200;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>bool enable_separate_recognition_per_channel = 12;</code>
       * @return This builder for chaining.
       */
      public Builder clearEnableSeparateRecognitionPerChannel() {
        bitField0_ = (bitField0_ & ~0x00000200);
        enableSeparateRecognitionPerChannel_ = false;
        onChanged();
        return this;
      }

      private Object model_ = "";
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>string model = 13;</code>
       * @return The model.
       */
      public String getModel() {
        Object ref = model_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          model_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>string model = 13;</code>
       * @return The bytes for model.
       */
      public com.google.protobuf.ByteString
          getModelBytes() {
        Object ref = model_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          model_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>string model = 13;</code>
       * @param value The model to set.
       * @return This builder for chaining.
       */
      public Builder setModel(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        model_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>string model = 13;</code>
       * @return This builder for chaining.
       */
      public Builder clearModel() {
        model_ = getDefaultInstance().getModel();
        bitField0_ = (bitField0_ & ~0x00000400);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>string model = 13;</code>
       * @param value The bytes for model to set.
       * @return This builder for chaining.
       */
      public Builder setModelBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        model_ = value;
        bitField0_ |= 0x00000400;
        onChanged();
        return this;
      }

      private boolean verbatimTranscripts_ ;
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>bool verbatim_transcripts = 14;</code>
       * @return The verbatimTranscripts.
       */
      @Override
      public boolean getVerbatimTranscripts() {
        return verbatimTranscripts_;
      }
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>bool verbatim_transcripts = 14;</code>
       * @param value The verbatimTranscripts to set.
       * @return This builder for chaining.
       */
      public Builder setVerbatimTranscripts(boolean value) {

        verbatimTranscripts_ = value;
        bitField0_ |= 0x00000800;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>bool verbatim_transcripts = 14;</code>
       * @return This builder for chaining.
       */
      public Builder clearVerbatimTranscripts() {
        bitField0_ = (bitField0_ & ~0x00000800);
        verbatimTranscripts_ = false;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          String, String> customConfiguration_;
      private com.google.protobuf.MapField<String, String>
          internalGetCustomConfiguration() {
        if (customConfiguration_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              CustomConfigurationDefaultEntryHolder.defaultEntry);
        }
        return customConfiguration_;
      }
      private com.google.protobuf.MapField<String, String>
          internalGetMutableCustomConfiguration() {
        if (customConfiguration_ == null) {
          customConfiguration_ = com.google.protobuf.MapField.newMapField(
              CustomConfigurationDefaultEntryHolder.defaultEntry);
        }
        if (!customConfiguration_.isMutable()) {
          customConfiguration_ = customConfiguration_.copy();
        }
        bitField0_ |= 0x00001000;
        onChanged();
        return customConfiguration_;
      }
      public int getCustomConfigurationCount() {
        return internalGetCustomConfiguration().getMap().size();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      @Override
      public boolean containsCustomConfiguration(
          String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        return internalGetCustomConfiguration().getMap().containsKey(key);
      }
      /**
       * Use {@link #getCustomConfigurationMap()} instead.
       */
      @Override
      @Deprecated
      public java.util.Map<String, String> getCustomConfiguration() {
        return getCustomConfigurationMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      @Override
      public java.util.Map<String, String> getCustomConfigurationMap() {
        return internalGetCustomConfiguration().getMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      @Override
      public /* nullable */
String getCustomConfigurationOrDefault(
          String key,
          /* nullable */
String defaultValue) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<String, String> map =
            internalGetCustomConfiguration().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      @Override
      public String getCustomConfigurationOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<String, String> map =
            internalGetCustomConfiguration().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }
      public Builder clearCustomConfiguration() {
        bitField0_ = (bitField0_ & ~0x00001000);
        internalGetMutableCustomConfiguration().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      public Builder removeCustomConfiguration(
          String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        internalGetMutableCustomConfiguration().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<String, String>
          getMutableCustomConfiguration() {
        bitField0_ |= 0x00001000;
        return internalGetMutableCustomConfiguration().getMutableMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      public Builder putCustomConfiguration(
          String key,
          String value) {
        if (key == null) { throw new NullPointerException("map key"); }
        if (value == null) { throw new NullPointerException("map value"); }
        internalGetMutableCustomConfiguration().getMutableMap()
            .put(key, value);
        bitField0_ |= 0x00001000;
        return this;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      public Builder putAllCustomConfiguration(
          java.util.Map<String, String> values) {
        internalGetMutableCustomConfiguration().getMutableMap()
            .putAll(values);
        bitField0_ |= 0x00001000;
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognitionConfig)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognitionConfig)
    private static final RecognitionConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new RecognitionConfig();
    }

    public static RecognitionConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognitionConfig>
        PARSER = new com.google.protobuf.AbstractParser<RecognitionConfig>() {
      @Override
      public RecognitionConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<RecognitionConfig> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<RecognitionConfig> getParserForType() {
      return PARSER;
    }

    @Override
    public RecognitionConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognitionConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognitionConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return Whether the config field is set.
     */
    boolean hasConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return The config.
     */
    RecognitionConfig getConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    RecognitionConfigOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * If `true`, interim results (tentative hypotheses) may be
     * returned as they become available (these interim results are indicated with
     * the `is_final=false` flag).
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>bool interim_results = 2;</code>
     * @return The interimResults.
     */
    boolean getInterimResults();
  }
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the request
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionConfig}
   */
  public static final class StreamingRecognitionConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognitionConfig)
      StreamingRecognitionConfigOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingRecognitionConfig.newBuilder() to construct.
    private StreamingRecognitionConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognitionConfig() {
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingRecognitionConfig();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              StreamingRecognitionConfig.class, Builder.class);
    }

    public static final int CONFIG_FIELD_NUMBER = 1;
    private RecognitionConfig config_;
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return Whether the config field is set.
     */
    @Override
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     * @return The config.
     */
    @Override
    public RecognitionConfig getConfig() {
      return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    @Override
    public RecognitionConfigOrBuilder getConfigOrBuilder() {
      return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
    }

    public static final int INTERIM_RESULTS_FIELD_NUMBER = 2;
    private boolean interimResults_ = false;
    /**
     * <pre>
     * If `true`, interim results (tentative hypotheses) may be
     * returned as they become available (these interim results are indicated with
     * the `is_final=false` flag).
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>bool interim_results = 2;</code>
     * @return The interimResults.
     */
    @Override
    public boolean getInterimResults() {
      return interimResults_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (config_ != null) {
        output.writeMessage(1, getConfig());
      }
      if (interimResults_ != false) {
        output.writeBool(2, interimResults_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getConfig());
      }
      if (interimResults_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, interimResults_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof StreamingRecognitionConfig)) {
        return super.equals(obj);
      }
      StreamingRecognitionConfig other = (StreamingRecognitionConfig) obj;

      if (hasConfig() != other.hasConfig()) return false;
      if (hasConfig()) {
        if (!getConfig()
            .equals(other.getConfig())) return false;
      }
      if (getInterimResults()
          != other.getInterimResults()) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + INTERIM_RESULTS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getInterimResults());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static StreamingRecognitionConfig parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionConfig parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognitionConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static StreamingRecognitionConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static StreamingRecognitionConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static StreamingRecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(StreamingRecognitionConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognitionConfig)
        StreamingRecognitionConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                StreamingRecognitionConfig.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.StreamingRecognitionConfig.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        config_ = null;
        if (configBuilder_ != null) {
          configBuilder_.dispose();
          configBuilder_ = null;
        }
        interimResults_ = false;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
      }

      @Override
      public StreamingRecognitionConfig getDefaultInstanceForType() {
        return StreamingRecognitionConfig.getDefaultInstance();
      }

      @Override
      public StreamingRecognitionConfig build() {
        StreamingRecognitionConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public StreamingRecognitionConfig buildPartial() {
        StreamingRecognitionConfig result = new StreamingRecognitionConfig(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(StreamingRecognitionConfig result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.config_ = configBuilder_ == null
              ? config_
              : configBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.interimResults_ = interimResults_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof StreamingRecognitionConfig) {
          return mergeFrom((StreamingRecognitionConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(StreamingRecognitionConfig other) {
        if (other == StreamingRecognitionConfig.getDefaultInstance()) return this;
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (other.getInterimResults() != false) {
          setInterimResults(other.getInterimResults());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                input.readMessage(
                    getConfigFieldBuilder().getBuilder(),
                    extensionRegistry);
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 16: {
                interimResults_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private RecognitionConfig config_;
      private com.google.protobuf.SingleFieldBuilderV3<
          RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder> configBuilder_;
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       * @return Whether the config field is set.
       */
      public boolean hasConfig() {
        return ((bitField0_ & 0x00000001) != 0);
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       * @return The config.
       */
      public RecognitionConfig getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? RecognitionConfig.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
        } else {
          configBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(
          RecognitionConfig.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder mergeConfig(RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0) &&
            config_ != null &&
            config_ != RecognitionConfig.getDefaultInstance()) {
            getConfigBuilder().mergeFrom(value);
          } else {
            config_ = value;
          }
        } else {
          configBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder clearConfig() {
        bitField0_ = (bitField0_ & ~0x00000001);
        config_ = null;
        if (configBuilder_ != null) {
          configBuilder_.dispose();
          configBuilder_ = null;
        }
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public RecognitionConfig.Builder getConfigBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public RecognitionConfigOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              RecognitionConfig.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>.nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder>
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              RecognitionConfig, RecognitionConfig.Builder, RecognitionConfigOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private boolean interimResults_ ;
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>bool interim_results = 2;</code>
       * @return The interimResults.
       */
      @Override
      public boolean getInterimResults() {
        return interimResults_;
      }
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>bool interim_results = 2;</code>
       * @param value The interimResults to set.
       * @return This builder for chaining.
       */
      public Builder setInterimResults(boolean value) {

        interimResults_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>bool interim_results = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearInterimResults() {
        bitField0_ = (bitField0_ & ~0x00000002);
        interimResults_ = false;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognitionConfig)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognitionConfig)
    private static final StreamingRecognitionConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new StreamingRecognitionConfig();
    }

    public static StreamingRecognitionConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognitionConfig>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognitionConfig>() {
      @Override
      public StreamingRecognitionConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognitionConfig> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingRecognitionConfig> getParserForType() {
      return PARSER;
    }

    @Override
    public StreamingRecognitionConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SpeechContextOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.SpeechContext)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @return A list containing the phrases.
     */
    java.util.List<String>
        getPhrasesList();
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @return The count of phrases.
     */
    int getPhrasesCount();
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @param index The index of the element to return.
     * @return The phrases at the given index.
     */
    String getPhrases(int index);
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the phrases at the given index.
     */
    com.google.protobuf.ByteString
        getPhrasesBytes(int index);

    /**
     * <pre>
     * Hint Boost. Positive value will increase the probability that a specific
     * phrase will be recognized over other similar sounding phrases. The higher
     * the boost, the higher the chance of false positive recognition as well.
     * Though `boost` can accept a wide range of positive values, most use cases are best served with
     * values between 0 and 20. We recommend using a binary search approach to
     * finding the optimal value for your use case.
     * </pre>
     *
     * <code>float boost = 4;</code>
     * @return The boost.
     */
    float getBoost();
  }
  /**
   * <pre>
   * Provides "hints" to the speech recognizer to favor specific words and phrases
   * in the results.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.SpeechContext}
   */
  public static final class SpeechContext extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.SpeechContext)
      SpeechContextOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SpeechContext.newBuilder() to construct.
    private SpeechContext(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SpeechContext() {
      phrases_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new SpeechContext();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechContext_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechContext_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              SpeechContext.class, Builder.class);
    }

    public static final int PHRASES_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private com.google.protobuf.LazyStringArrayList phrases_ =
        com.google.protobuf.LazyStringArrayList.emptyList();
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @return A list containing the phrases.
     */
    public com.google.protobuf.ProtocolStringList
        getPhrasesList() {
      return phrases_;
    }
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @return The count of phrases.
     */
    public int getPhrasesCount() {
      return phrases_.size();
    }
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @param index The index of the element to return.
     * @return The phrases at the given index.
     */
    public String getPhrases(int index) {
      return phrases_.get(index);
    }
    /**
     * <pre>
     * A list of strings containing words and phrases "hints" so that
     * the speech recognition is more likely to recognize them. This can be used
     * to improve the accuracy for specific words and phrases, for example, if
     * specific commands are typically spoken by the user. This can also be used
     * to add additional words to the vocabulary of the recognizer. 
     * </pre>
     *
     * <code>repeated string phrases = 1;</code>
     * @param index The index of the value to return.
     * @return The bytes of the phrases at the given index.
     */
    public com.google.protobuf.ByteString
        getPhrasesBytes(int index) {
      return phrases_.getByteString(index);
    }

    public static final int BOOST_FIELD_NUMBER = 4;
    private float boost_ = 0F;
    /**
     * <pre>
     * Hint Boost. Positive value will increase the probability that a specific
     * phrase will be recognized over other similar sounding phrases. The higher
     * the boost, the higher the chance of false positive recognition as well.
     * Though `boost` can accept a wide range of positive values, most use cases are best served with
     * values between 0 and 20. We recommend using a binary search approach to
     * finding the optimal value for your use case.
     * </pre>
     *
     * <code>float boost = 4;</code>
     * @return The boost.
     */
    @Override
    public float getBoost() {
      return boost_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < phrases_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, phrases_.getRaw(i));
      }
      if (Float.floatToRawIntBits(boost_) != 0) {
        output.writeFloat(4, boost_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < phrases_.size(); i++) {
          dataSize += computeStringSizeNoTag(phrases_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getPhrasesList().size();
      }
      if (Float.floatToRawIntBits(boost_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, boost_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof SpeechContext)) {
        return super.equals(obj);
      }
      SpeechContext other = (SpeechContext) obj;

      if (!getPhrasesList()
          .equals(other.getPhrasesList())) return false;
      if (Float.floatToIntBits(getBoost())
          != Float.floatToIntBits(
              other.getBoost())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getPhrasesCount() > 0) {
        hash = (37 * hash) + PHRASES_FIELD_NUMBER;
        hash = (53 * hash) + getPhrasesList().hashCode();
      }
      hash = (37 * hash) + BOOST_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getBoost());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static SpeechContext parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechContext parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechContext parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechContext parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechContext parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechContext parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechContext parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechContext parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static SpeechContext parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static SpeechContext parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static SpeechContext parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechContext parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(SpeechContext prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides "hints" to the speech recognizer to favor specific words and phrases
     * in the results.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.SpeechContext}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.SpeechContext)
        SpeechContextOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechContext_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechContext_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                SpeechContext.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.SpeechContext.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        phrases_ =
            com.google.protobuf.LazyStringArrayList.emptyList();
        boost_ = 0F;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechContext_descriptor;
      }

      @Override
      public SpeechContext getDefaultInstanceForType() {
        return SpeechContext.getDefaultInstance();
      }

      @Override
      public SpeechContext build() {
        SpeechContext result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public SpeechContext buildPartial() {
        SpeechContext result = new SpeechContext(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(SpeechContext result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          phrases_.makeImmutable();
          result.phrases_ = phrases_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.boost_ = boost_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof SpeechContext) {
          return mergeFrom((SpeechContext)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(SpeechContext other) {
        if (other == SpeechContext.getDefaultInstance()) return this;
        if (!other.phrases_.isEmpty()) {
          if (phrases_.isEmpty()) {
            phrases_ = other.phrases_;
            bitField0_ |= 0x00000001;
          } else {
            ensurePhrasesIsMutable();
            phrases_.addAll(other.phrases_);
          }
          onChanged();
        }
        if (other.getBoost() != 0F) {
          setBoost(other.getBoost());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                String s = input.readStringRequireUtf8();
                ensurePhrasesIsMutable();
                phrases_.add(s);
                break;
              } // case 10
              case 37: {
                boost_ = input.readFloat();
                bitField0_ |= 0x00000002;
                break;
              } // case 37
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringArrayList phrases_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
      private void ensurePhrasesIsMutable() {
        if (!phrases_.isModifiable()) {
          phrases_ = new com.google.protobuf.LazyStringArrayList(phrases_);
        }
        bitField0_ |= 0x00000001;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @return A list containing the phrases.
       */
      public com.google.protobuf.ProtocolStringList
          getPhrasesList() {
        phrases_.makeImmutable();
        return phrases_;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @return The count of phrases.
       */
      public int getPhrasesCount() {
        return phrases_.size();
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param index The index of the element to return.
       * @return The phrases at the given index.
       */
      public String getPhrases(int index) {
        return phrases_.get(index);
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param index The index of the value to return.
       * @return The bytes of the phrases at the given index.
       */
      public com.google.protobuf.ByteString
          getPhrasesBytes(int index) {
        return phrases_.getByteString(index);
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param index The index to set the value at.
       * @param value The phrases to set.
       * @return This builder for chaining.
       */
      public Builder setPhrases(
          int index, String value) {
        if (value == null) { throw new NullPointerException(); }
        ensurePhrasesIsMutable();
        phrases_.set(index, value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param value The phrases to add.
       * @return This builder for chaining.
       */
      public Builder addPhrases(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        ensurePhrasesIsMutable();
        phrases_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param values The phrases to add.
       * @return This builder for chaining.
       */
      public Builder addAllPhrases(
          Iterable<String> values) {
        ensurePhrasesIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, phrases_);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearPhrases() {
        phrases_ =
          com.google.protobuf.LazyStringArrayList.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * A list of strings containing words and phrases "hints" so that
       * the speech recognition is more likely to recognize them. This can be used
       * to improve the accuracy for specific words and phrases, for example, if
       * specific commands are typically spoken by the user. This can also be used
       * to add additional words to the vocabulary of the recognizer. 
       * </pre>
       *
       * <code>repeated string phrases = 1;</code>
       * @param value The bytes of the phrases to add.
       * @return This builder for chaining.
       */
      public Builder addPhrasesBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        ensurePhrasesIsMutable();
        phrases_.add(value);
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private float boost_ ;
      /**
       * <pre>
       * Hint Boost. Positive value will increase the probability that a specific
       * phrase will be recognized over other similar sounding phrases. The higher
       * the boost, the higher the chance of false positive recognition as well.
       * Though `boost` can accept a wide range of positive values, most use cases are best served with
       * values between 0 and 20. We recommend using a binary search approach to
       * finding the optimal value for your use case.
       * </pre>
       *
       * <code>float boost = 4;</code>
       * @return The boost.
       */
      @Override
      public float getBoost() {
        return boost_;
      }
      /**
       * <pre>
       * Hint Boost. Positive value will increase the probability that a specific
       * phrase will be recognized over other similar sounding phrases. The higher
       * the boost, the higher the chance of false positive recognition as well.
       * Though `boost` can accept a wide range of positive values, most use cases are best served with
       * values between 0 and 20. We recommend using a binary search approach to
       * finding the optimal value for your use case.
       * </pre>
       *
       * <code>float boost = 4;</code>
       * @param value The boost to set.
       * @return This builder for chaining.
       */
      public Builder setBoost(float value) {

        boost_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Hint Boost. Positive value will increase the probability that a specific
       * phrase will be recognized over other similar sounding phrases. The higher
       * the boost, the higher the chance of false positive recognition as well.
       * Though `boost` can accept a wide range of positive values, most use cases are best served with
       * values between 0 and 20. We recommend using a binary search approach to
       * finding the optimal value for your use case.
       * </pre>
       *
       * <code>float boost = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearBoost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        boost_ = 0F;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.SpeechContext)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.SpeechContext)
    private static final SpeechContext DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new SpeechContext();
    }

    public static SpeechContext getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SpeechContext>
        PARSER = new com.google.protobuf.AbstractParser<SpeechContext>() {
      @Override
      public SpeechContext parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SpeechContext> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<SpeechContext> getParserForType() {
      return PARSER;
    }

    @Override
    public SpeechContext getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecognizeResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognizeResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    java.util.List<SpeechRecognitionResult>
        getResultsList();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    SpeechRecognitionResult getResults(int index);
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    int getResultsCount();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    java.util.List<? extends SpeechRecognitionResultOrBuilder>
        getResultsOrBuilderList();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    SpeechRecognitionResultOrBuilder getResultsOrBuilder(
        int index);
  }
  /**
   * <pre>
   * The only message returned to the client by the `Recognize` method. It
   * contains the result as zero or more sequential `SpeechRecognitionResult`
   * messages.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognizeResponse}
   */
  public static final class RecognizeResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognizeResponse)
      RecognizeResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use RecognizeResponse.newBuilder() to construct.
    private RecognizeResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognizeResponse() {
      results_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new RecognizeResponse();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              RecognizeResponse.class, Builder.class);
    }

    public static final int RESULTS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<SpeechRecognitionResult> results_;
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    @Override
    public java.util.List<SpeechRecognitionResult> getResultsList() {
      return results_;
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    @Override
    public java.util.List<? extends SpeechRecognitionResultOrBuilder>
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    @Override
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    @Override
    public SpeechRecognitionResult getResults(int index) {
      return results_.get(index);
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    @Override
    public SpeechRecognitionResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(1, results_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < results_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, results_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof RecognizeResponse)) {
        return super.equals(obj);
      }
      RecognizeResponse other = (RecognizeResponse) obj;

      if (!getResultsList()
          .equals(other.getResultsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static RecognizeResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static RecognizeResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static RecognizeResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognizeResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static RecognizeResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static RecognizeResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static RecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static RecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(RecognizeResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * The only message returned to the client by the `Recognize` method. It
     * contains the result as zero or more sequential `SpeechRecognitionResult`
     * messages.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognizeResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognizeResponse)
        RecognizeResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                RecognizeResponse.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.RecognizeResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
        } else {
          results_ = null;
          resultsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
      }

      @Override
      public RecognizeResponse getDefaultInstanceForType() {
        return RecognizeResponse.getDefaultInstance();
      }

      @Override
      public RecognizeResponse build() {
        RecognizeResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public RecognizeResponse buildPartial() {
        RecognizeResponse result = new RecognizeResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(RecognizeResponse result) {
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
      }

      private void buildPartial0(RecognizeResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof RecognizeResponse) {
          return mergeFrom((RecognizeResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(RecognizeResponse other) {
        if (other == RecognizeResponse.getDefaultInstance()) return this;
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                SpeechRecognitionResult m =
                    input.readMessage(
                        SpeechRecognitionResult.parser(),
                        extensionRegistry);
                if (resultsBuilder_ == null) {
                  ensureResultsIsMutable();
                  results_.add(m);
                } else {
                  resultsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<SpeechRecognitionResult> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          results_ = new java.util.ArrayList<SpeechRecognitionResult>(results_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionResult, SpeechRecognitionResult.Builder, SpeechRecognitionResultOrBuilder> resultsBuilder_;

      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<SpeechRecognitionResult> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public SpeechRecognitionResult getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addAllResults(
          Iterable<? extends SpeechRecognitionResult> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public SpeechRecognitionResult.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public SpeechRecognitionResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<? extends SpeechRecognitionResultOrBuilder>
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public SpeechRecognitionResult.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            SpeechRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public SpeechRecognitionResult.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, SpeechRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<SpeechRecognitionResult.Builder>
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionResult, SpeechRecognitionResult.Builder, SpeechRecognitionResultOrBuilder>
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              SpeechRecognitionResult, SpeechRecognitionResult.Builder, SpeechRecognitionResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognizeResponse)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognizeResponse)
    private static final RecognizeResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new RecognizeResponse();
    }

    public static RecognizeResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognizeResponse>
        PARSER = new com.google.protobuf.AbstractParser<RecognizeResponse>() {
      @Override
      public RecognizeResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<RecognizeResponse> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<RecognizeResponse> getParserForType() {
      return PARSER;
    }

    @Override
    public RecognizeResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SpeechRecognitionResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.SpeechRecognitionResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<SpeechRecognitionAlternative>
        getAlternativesList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    SpeechRecognitionAlternative getAlternatives(int index);
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    int getAlternativesCount();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
        getAlternativesOrBuilderList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index);

    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>int32 channel_tag = 2;</code>
     * @return The channelTag.
     */
    int getChannelTag();

    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>float audio_processed = 3;</code>
     * @return The audioProcessed.
     */
    float getAudioProcessed();
  }
  /**
   * <pre>
   * A speech recognition result corresponding to the latest transcript
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionResult}
   */
  public static final class SpeechRecognitionResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.SpeechRecognitionResult)
      SpeechRecognitionResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SpeechRecognitionResult.newBuilder() to construct.
    private SpeechRecognitionResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SpeechRecognitionResult() {
      alternatives_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new SpeechRecognitionResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              SpeechRecognitionResult.class, Builder.class);
    }

    public static final int ALTERNATIVES_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<SpeechRecognitionAlternative> alternatives_;
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public java.util.List<SpeechRecognitionAlternative> getAlternativesList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
        getAlternativesOrBuilderList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public int getAlternativesCount() {
      return alternatives_.size();
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public SpeechRecognitionAlternative getAlternatives(int index) {
      return alternatives_.get(index);
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index) {
      return alternatives_.get(index);
    }

    public static final int CHANNEL_TAG_FIELD_NUMBER = 2;
    private int channelTag_ = 0;
    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>int32 channel_tag = 2;</code>
     * @return The channelTag.
     */
    @Override
    public int getChannelTag() {
      return channelTag_;
    }

    public static final int AUDIO_PROCESSED_FIELD_NUMBER = 3;
    private float audioProcessed_ = 0F;
    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>float audio_processed = 3;</code>
     * @return The audioProcessed.
     */
    @Override
    public float getAudioProcessed() {
      return audioProcessed_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < alternatives_.size(); i++) {
        output.writeMessage(1, alternatives_.get(i));
      }
      if (channelTag_ != 0) {
        output.writeInt32(2, channelTag_);
      }
      if (Float.floatToRawIntBits(audioProcessed_) != 0) {
        output.writeFloat(3, audioProcessed_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < alternatives_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, alternatives_.get(i));
      }
      if (channelTag_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, channelTag_);
      }
      if (Float.floatToRawIntBits(audioProcessed_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, audioProcessed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof SpeechRecognitionResult)) {
        return super.equals(obj);
      }
      SpeechRecognitionResult other = (SpeechRecognitionResult) obj;

      if (!getAlternativesList()
          .equals(other.getAlternativesList())) return false;
      if (getChannelTag()
          != other.getChannelTag()) return false;
      if (Float.floatToIntBits(getAudioProcessed())
          != Float.floatToIntBits(
              other.getAudioProcessed())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getAlternativesCount() > 0) {
        hash = (37 * hash) + ALTERNATIVES_FIELD_NUMBER;
        hash = (53 * hash) + getAlternativesList().hashCode();
      }
      hash = (37 * hash) + CHANNEL_TAG_FIELD_NUMBER;
      hash = (53 * hash) + getChannelTag();
      hash = (37 * hash) + AUDIO_PROCESSED_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getAudioProcessed());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static SpeechRecognitionResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechRecognitionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static SpeechRecognitionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static SpeechRecognitionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static SpeechRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(SpeechRecognitionResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A speech recognition result corresponding to the latest transcript
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.SpeechRecognitionResult)
        SpeechRecognitionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                SpeechRecognitionResult.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.SpeechRecognitionResult.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
        } else {
          alternatives_ = null;
          alternativesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        channelTag_ = 0;
        audioProcessed_ = 0F;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
      }

      @Override
      public SpeechRecognitionResult getDefaultInstanceForType() {
        return SpeechRecognitionResult.getDefaultInstance();
      }

      @Override
      public SpeechRecognitionResult build() {
        SpeechRecognitionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public SpeechRecognitionResult buildPartial() {
        SpeechRecognitionResult result = new SpeechRecognitionResult(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(SpeechRecognitionResult result) {
        if (alternativesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.alternatives_ = alternatives_;
        } else {
          result.alternatives_ = alternativesBuilder_.build();
        }
      }

      private void buildPartial0(SpeechRecognitionResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.channelTag_ = channelTag_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.audioProcessed_ = audioProcessed_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof SpeechRecognitionResult) {
          return mergeFrom((SpeechRecognitionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(SpeechRecognitionResult other) {
        if (other == SpeechRecognitionResult.getDefaultInstance()) return this;
        if (alternativesBuilder_ == null) {
          if (!other.alternatives_.isEmpty()) {
            if (alternatives_.isEmpty()) {
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAlternativesIsMutable();
              alternatives_.addAll(other.alternatives_);
            }
            onChanged();
          }
        } else {
          if (!other.alternatives_.isEmpty()) {
            if (alternativesBuilder_.isEmpty()) {
              alternativesBuilder_.dispose();
              alternativesBuilder_ = null;
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
              alternativesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAlternativesFieldBuilder() : null;
            } else {
              alternativesBuilder_.addAllMessages(other.alternatives_);
            }
          }
        }
        if (other.getChannelTag() != 0) {
          setChannelTag(other.getChannelTag());
        }
        if (other.getAudioProcessed() != 0F) {
          setAudioProcessed(other.getAudioProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                SpeechRecognitionAlternative m =
                    input.readMessage(
                        SpeechRecognitionAlternative.parser(),
                        extensionRegistry);
                if (alternativesBuilder_ == null) {
                  ensureAlternativesIsMutable();
                  alternatives_.add(m);
                } else {
                  alternativesBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                channelTag_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 29: {
                audioProcessed_ = input.readFloat();
                bitField0_ |= 0x00000004;
                break;
              } // case 29
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<SpeechRecognitionAlternative> alternatives_ =
        java.util.Collections.emptyList();
      private void ensureAlternativesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          alternatives_ = new java.util.ArrayList<SpeechRecognitionAlternative>(alternatives_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder> alternativesBuilder_;

      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<SpeechRecognitionAlternative> getAlternativesList() {
        if (alternativesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(alternatives_);
        } else {
          return alternativesBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public int getAlternativesCount() {
        if (alternativesBuilder_ == null) {
          return alternatives_.size();
        } else {
          return alternativesBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative getAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);
        } else {
          return alternativesBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.set(index, value);
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.set(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(index, value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAllAlternatives(
          Iterable<? extends SpeechRecognitionAlternative> values) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, alternatives_);
          onChanged();
        } else {
          alternativesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder clearAlternatives() {
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          alternativesBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder removeAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.remove(index);
          onChanged();
        } else {
          alternativesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder getAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
          int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);  } else {
          return alternativesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
           getAlternativesOrBuilderList() {
        if (alternativesBuilder_ != null) {
          return alternativesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(alternatives_);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder addAlternativesBuilder() {
        return getAlternativesFieldBuilder().addBuilder(
            SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder addAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().addBuilder(
            index, SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<SpeechRecognitionAlternative.Builder>
           getAlternativesBuilderList() {
        return getAlternativesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder>
          getAlternativesFieldBuilder() {
        if (alternativesBuilder_ == null) {
          alternativesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder>(
                  alternatives_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          alternatives_ = null;
        }
        return alternativesBuilder_;
      }

      private int channelTag_ ;
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 2;</code>
       * @return The channelTag.
       */
      @Override
      public int getChannelTag() {
        return channelTag_;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 2;</code>
       * @param value The channelTag to set.
       * @return This builder for chaining.
       */
      public Builder setChannelTag(int value) {

        channelTag_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearChannelTag() {
        bitField0_ = (bitField0_ & ~0x00000002);
        channelTag_ = 0;
        onChanged();
        return this;
      }

      private float audioProcessed_ ;
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 3;</code>
       * @return The audioProcessed.
       */
      @Override
      public float getAudioProcessed() {
        return audioProcessed_;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 3;</code>
       * @param value The audioProcessed to set.
       * @return This builder for chaining.
       */
      public Builder setAudioProcessed(float value) {

        audioProcessed_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioProcessed() {
        bitField0_ = (bitField0_ & ~0x00000004);
        audioProcessed_ = 0F;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.SpeechRecognitionResult)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.SpeechRecognitionResult)
    private static final SpeechRecognitionResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new SpeechRecognitionResult();
    }

    public static SpeechRecognitionResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SpeechRecognitionResult>
        PARSER = new com.google.protobuf.AbstractParser<SpeechRecognitionResult>() {
      @Override
      public SpeechRecognitionResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SpeechRecognitionResult> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<SpeechRecognitionResult> getParserForType() {
      return PARSER;
    }

    @Override
    public SpeechRecognitionResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SpeechRecognitionAlternativeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.SpeechRecognitionAlternative)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>string transcript = 1;</code>
     * @return The transcript.
     */
    String getTranscript();
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>string transcript = 1;</code>
     * @return The bytes for transcript.
     */
    com.google.protobuf.ByteString
        getTranscriptBytes();

    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number
     * indicates an estimated greater likelihood that the recognized words are
     * correct. This field is set only for a non-streaming
     * result or, of a streaming result where `is_final=true`.
     * This field is not guaranteed to be accurate and users should not rely on it
     * to be always provided.
     * </pre>
     *
     * <code>float confidence = 2;</code>
     * @return The confidence.
     */
    float getConfidence();

    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    java.util.List<WordInfo>
        getWordsList();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    WordInfo getWords(int index);
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    int getWordsCount();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    java.util.List<? extends WordInfoOrBuilder>
        getWordsOrBuilderList();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    WordInfoOrBuilder getWordsOrBuilder(
        int index);
  }
  /**
   * <pre>
   * Alternative hypotheses (a.k.a. n-best list).
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionAlternative}
   */
  public static final class SpeechRecognitionAlternative extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.SpeechRecognitionAlternative)
      SpeechRecognitionAlternativeOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SpeechRecognitionAlternative.newBuilder() to construct.
    private SpeechRecognitionAlternative(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SpeechRecognitionAlternative() {
      transcript_ = "";
      words_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new SpeechRecognitionAlternative();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              SpeechRecognitionAlternative.class, Builder.class);
    }

    public static final int TRANSCRIPT_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private volatile Object transcript_ = "";
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>string transcript = 1;</code>
     * @return The transcript.
     */
    @Override
    public String getTranscript() {
      Object ref = transcript_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        transcript_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>string transcript = 1;</code>
     * @return The bytes for transcript.
     */
    @Override
    public com.google.protobuf.ByteString
        getTranscriptBytes() {
      Object ref = transcript_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        transcript_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CONFIDENCE_FIELD_NUMBER = 2;
    private float confidence_ = 0F;
    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number
     * indicates an estimated greater likelihood that the recognized words are
     * correct. This field is set only for a non-streaming
     * result or, of a streaming result where `is_final=true`.
     * This field is not guaranteed to be accurate and users should not rely on it
     * to be always provided.
     * </pre>
     *
     * <code>float confidence = 2;</code>
     * @return The confidence.
     */
    @Override
    public float getConfidence() {
      return confidence_;
    }

    public static final int WORDS_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private java.util.List<WordInfo> words_;
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    @Override
    public java.util.List<WordInfo> getWordsList() {
      return words_;
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    @Override
    public java.util.List<? extends WordInfoOrBuilder>
        getWordsOrBuilderList() {
      return words_;
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    @Override
    public int getWordsCount() {
      return words_.size();
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    @Override
    public WordInfo getWords(int index) {
      return words_.get(index);
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    @Override
    public WordInfoOrBuilder getWordsOrBuilder(
        int index) {
      return words_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(transcript_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, transcript_);
      }
      if (Float.floatToRawIntBits(confidence_) != 0) {
        output.writeFloat(2, confidence_);
      }
      for (int i = 0; i < words_.size(); i++) {
        output.writeMessage(3, words_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(transcript_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, transcript_);
      }
      if (Float.floatToRawIntBits(confidence_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, confidence_);
      }
      for (int i = 0; i < words_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, words_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof SpeechRecognitionAlternative)) {
        return super.equals(obj);
      }
      SpeechRecognitionAlternative other = (SpeechRecognitionAlternative) obj;

      if (!getTranscript()
          .equals(other.getTranscript())) return false;
      if (Float.floatToIntBits(getConfidence())
          != Float.floatToIntBits(
              other.getConfidence())) return false;
      if (!getWordsList()
          .equals(other.getWordsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + TRANSCRIPT_FIELD_NUMBER;
      hash = (53 * hash) + getTranscript().hashCode();
      hash = (37 * hash) + CONFIDENCE_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getConfidence());
      if (getWordsCount() > 0) {
        hash = (37 * hash) + WORDS_FIELD_NUMBER;
        hash = (53 * hash) + getWordsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static SpeechRecognitionAlternative parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionAlternative parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionAlternative parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static SpeechRecognitionAlternative parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static SpeechRecognitionAlternative parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechRecognitionAlternative parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static SpeechRecognitionAlternative parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static SpeechRecognitionAlternative parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(SpeechRecognitionAlternative prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Alternative hypotheses (a.k.a. n-best list).
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionAlternative}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.SpeechRecognitionAlternative)
        SpeechRecognitionAlternativeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                SpeechRecognitionAlternative.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.SpeechRecognitionAlternative.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        transcript_ = "";
        confidence_ = 0F;
        if (wordsBuilder_ == null) {
          words_ = java.util.Collections.emptyList();
        } else {
          words_ = null;
          wordsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
      }

      @Override
      public SpeechRecognitionAlternative getDefaultInstanceForType() {
        return SpeechRecognitionAlternative.getDefaultInstance();
      }

      @Override
      public SpeechRecognitionAlternative build() {
        SpeechRecognitionAlternative result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public SpeechRecognitionAlternative buildPartial() {
        SpeechRecognitionAlternative result = new SpeechRecognitionAlternative(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(SpeechRecognitionAlternative result) {
        if (wordsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) != 0)) {
            words_ = java.util.Collections.unmodifiableList(words_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.words_ = words_;
        } else {
          result.words_ = wordsBuilder_.build();
        }
      }

      private void buildPartial0(SpeechRecognitionAlternative result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.transcript_ = transcript_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.confidence_ = confidence_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof SpeechRecognitionAlternative) {
          return mergeFrom((SpeechRecognitionAlternative)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(SpeechRecognitionAlternative other) {
        if (other == SpeechRecognitionAlternative.getDefaultInstance()) return this;
        if (!other.getTranscript().isEmpty()) {
          transcript_ = other.transcript_;
          bitField0_ |= 0x00000001;
          onChanged();
        }
        if (other.getConfidence() != 0F) {
          setConfidence(other.getConfidence());
        }
        if (wordsBuilder_ == null) {
          if (!other.words_.isEmpty()) {
            if (words_.isEmpty()) {
              words_ = other.words_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureWordsIsMutable();
              words_.addAll(other.words_);
            }
            onChanged();
          }
        } else {
          if (!other.words_.isEmpty()) {
            if (wordsBuilder_.isEmpty()) {
              wordsBuilder_.dispose();
              wordsBuilder_ = null;
              words_ = other.words_;
              bitField0_ = (bitField0_ & ~0x00000004);
              wordsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getWordsFieldBuilder() : null;
            } else {
              wordsBuilder_.addAllMessages(other.words_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                transcript_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000001;
                break;
              } // case 10
              case 21: {
                confidence_ = input.readFloat();
                bitField0_ |= 0x00000002;
                break;
              } // case 21
              case 26: {
                WordInfo m =
                    input.readMessage(
                        WordInfo.parser(),
                        extensionRegistry);
                if (wordsBuilder_ == null) {
                  ensureWordsIsMutable();
                  words_.add(m);
                } else {
                  wordsBuilder_.addMessage(m);
                }
                break;
              } // case 26
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private Object transcript_ = "";
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>string transcript = 1;</code>
       * @return The transcript.
       */
      public String getTranscript() {
        Object ref = transcript_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          transcript_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>string transcript = 1;</code>
       * @return The bytes for transcript.
       */
      public com.google.protobuf.ByteString
          getTranscriptBytes() {
        Object ref = transcript_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          transcript_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>string transcript = 1;</code>
       * @param value The transcript to set.
       * @return This builder for chaining.
       */
      public Builder setTranscript(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        transcript_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>string transcript = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearTranscript() {
        transcript_ = getDefaultInstance().getTranscript();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>string transcript = 1;</code>
       * @param value The bytes for transcript to set.
       * @return This builder for chaining.
       */
      public Builder setTranscriptBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        transcript_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }

      private float confidence_ ;
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>float confidence = 2;</code>
       * @return The confidence.
       */
      @Override
      public float getConfidence() {
        return confidence_;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>float confidence = 2;</code>
       * @param value The confidence to set.
       * @return This builder for chaining.
       */
      public Builder setConfidence(float value) {

        confidence_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>float confidence = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearConfidence() {
        bitField0_ = (bitField0_ & ~0x00000002);
        confidence_ = 0F;
        onChanged();
        return this;
      }

      private java.util.List<WordInfo> words_ =
        java.util.Collections.emptyList();
      private void ensureWordsIsMutable() {
        if (!((bitField0_ & 0x00000004) != 0)) {
          words_ = new java.util.ArrayList<WordInfo>(words_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          WordInfo, WordInfo.Builder, WordInfoOrBuilder> wordsBuilder_;

      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<WordInfo> getWordsList() {
        if (wordsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(words_);
        } else {
          return wordsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public int getWordsCount() {
        if (wordsBuilder_ == null) {
          return words_.size();
        } else {
          return wordsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public WordInfo getWords(int index) {
        if (wordsBuilder_ == null) {
          return words_.get(index);
        } else {
          return wordsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder setWords(
          int index, WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.set(index, value);
          onChanged();
        } else {
          wordsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder setWords(
          int index, WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.set(index, builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.add(value);
          onChanged();
        } else {
          wordsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          int index, WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.add(index, value);
          onChanged();
        } else {
          wordsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.add(builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          int index, WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.add(index, builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addAllWords(
          Iterable<? extends WordInfo> values) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, words_);
          onChanged();
        } else {
          wordsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder clearWords() {
        if (wordsBuilder_ == null) {
          words_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          wordsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder removeWords(int index) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.remove(index);
          onChanged();
        } else {
          wordsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public WordInfo.Builder getWordsBuilder(
          int index) {
        return getWordsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public WordInfoOrBuilder getWordsOrBuilder(
          int index) {
        if (wordsBuilder_ == null) {
          return words_.get(index);  } else {
          return wordsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<? extends WordInfoOrBuilder>
           getWordsOrBuilderList() {
        if (wordsBuilder_ != null) {
          return wordsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(words_);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public WordInfo.Builder addWordsBuilder() {
        return getWordsFieldBuilder().addBuilder(
            WordInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public WordInfo.Builder addWordsBuilder(
          int index) {
        return getWordsFieldBuilder().addBuilder(
            index, WordInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<WordInfo.Builder>
           getWordsBuilderList() {
        return getWordsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          WordInfo, WordInfo.Builder, WordInfoOrBuilder>
          getWordsFieldBuilder() {
        if (wordsBuilder_ == null) {
          wordsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              WordInfo, WordInfo.Builder, WordInfoOrBuilder>(
                  words_,
                  ((bitField0_ & 0x00000004) != 0),
                  getParentForChildren(),
                  isClean());
          words_ = null;
        }
        return wordsBuilder_;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.SpeechRecognitionAlternative)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.SpeechRecognitionAlternative)
    private static final SpeechRecognitionAlternative DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new SpeechRecognitionAlternative();
    }

    public static SpeechRecognitionAlternative getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SpeechRecognitionAlternative>
        PARSER = new com.google.protobuf.AbstractParser<SpeechRecognitionAlternative>() {
      @Override
      public SpeechRecognitionAlternative parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<SpeechRecognitionAlternative> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<SpeechRecognitionAlternative> getParserForType() {
      return PARSER;
    }

    @Override
    public SpeechRecognitionAlternative getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WordInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.WordInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the start of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>int32 start_time = 1;</code>
     * @return The startTime.
     */
    int getStartTime();

    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the end of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>int32 end_time = 2;</code>
     * @return The endTime.
     */
    int getEndTime();

    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>string word = 3;</code>
     * @return The word.
     */
    String getWord();
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>string word = 3;</code>
     * @return The bytes for word.
     */
    com.google.protobuf.ByteString
        getWordBytes();

    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number indicates an
     * estimated greater likelihood that the recognized words are correct. This
     * field is not guaranteed to be accurate and users should not rely on it to
     * be always provided. The default of 0.0 is a sentinel value indicating
     * confidence was not set. 
     * </pre>
     *
     * <code>float confidence = 4;</code>
     * @return The confidence.
     */
    float getConfidence();
  }
  /**
   * <pre>
   * Word-specific information for recognized words.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.WordInfo}
   */
  public static final class WordInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.WordInfo)
      WordInfoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use WordInfo.newBuilder() to construct.
    private WordInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WordInfo() {
      word_ = "";
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new WordInfo();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              WordInfo.class, Builder.class);
    }

    public static final int START_TIME_FIELD_NUMBER = 1;
    private int startTime_ = 0;
    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the start of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>int32 start_time = 1;</code>
     * @return The startTime.
     */
    @Override
    public int getStartTime() {
      return startTime_;
    }

    public static final int END_TIME_FIELD_NUMBER = 2;
    private int endTime_ = 0;
    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the end of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>int32 end_time = 2;</code>
     * @return The endTime.
     */
    @Override
    public int getEndTime() {
      return endTime_;
    }

    public static final int WORD_FIELD_NUMBER = 3;
    @SuppressWarnings("serial")
    private volatile Object word_ = "";
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>string word = 3;</code>
     * @return The word.
     */
    @Override
    public String getWord() {
      Object ref = word_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        word_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>string word = 3;</code>
     * @return The bytes for word.
     */
    @Override
    public com.google.protobuf.ByteString
        getWordBytes() {
      Object ref = word_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        word_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CONFIDENCE_FIELD_NUMBER = 4;
    private float confidence_ = 0F;
    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number indicates an
     * estimated greater likelihood that the recognized words are correct. This
     * field is not guaranteed to be accurate and users should not rely on it to
     * be always provided. The default of 0.0 is a sentinel value indicating
     * confidence was not set. 
     * </pre>
     *
     * <code>float confidence = 4;</code>
     * @return The confidence.
     */
    @Override
    public float getConfidence() {
      return confidence_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (startTime_ != 0) {
        output.writeInt32(1, startTime_);
      }
      if (endTime_ != 0) {
        output.writeInt32(2, endTime_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(word_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, word_);
      }
      if (Float.floatToRawIntBits(confidence_) != 0) {
        output.writeFloat(4, confidence_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (startTime_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, startTime_);
      }
      if (endTime_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, endTime_);
      }
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(word_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, word_);
      }
      if (Float.floatToRawIntBits(confidence_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, confidence_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof WordInfo)) {
        return super.equals(obj);
      }
      WordInfo other = (WordInfo) obj;

      if (getStartTime()
          != other.getStartTime()) return false;
      if (getEndTime()
          != other.getEndTime()) return false;
      if (!getWord()
          .equals(other.getWord())) return false;
      if (Float.floatToIntBits(getConfidence())
          != Float.floatToIntBits(
              other.getConfidence())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + START_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getStartTime();
      hash = (37 * hash) + END_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getEndTime();
      hash = (37 * hash) + WORD_FIELD_NUMBER;
      hash = (53 * hash) + getWord().hashCode();
      hash = (37 * hash) + CONFIDENCE_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getConfidence());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static WordInfo parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static WordInfo parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static WordInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static WordInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static WordInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static WordInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static WordInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static WordInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static WordInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static WordInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static WordInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static WordInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(WordInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Word-specific information for recognized words.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.WordInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.WordInfo)
        WordInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                WordInfo.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.WordInfo.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        startTime_ = 0;
        endTime_ = 0;
        word_ = "";
        confidence_ = 0F;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
      }

      @Override
      public WordInfo getDefaultInstanceForType() {
        return WordInfo.getDefaultInstance();
      }

      @Override
      public WordInfo build() {
        WordInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public WordInfo buildPartial() {
        WordInfo result = new WordInfo(this);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartial0(WordInfo result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000001) != 0)) {
          result.startTime_ = startTime_;
        }
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.endTime_ = endTime_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.word_ = word_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.confidence_ = confidence_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof WordInfo) {
          return mergeFrom((WordInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(WordInfo other) {
        if (other == WordInfo.getDefaultInstance()) return this;
        if (other.getStartTime() != 0) {
          setStartTime(other.getStartTime());
        }
        if (other.getEndTime() != 0) {
          setEndTime(other.getEndTime());
        }
        if (!other.getWord().isEmpty()) {
          word_ = other.word_;
          bitField0_ |= 0x00000004;
          onChanged();
        }
        if (other.getConfidence() != 0F) {
          setConfidence(other.getConfidence());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 8: {
                startTime_ = input.readInt32();
                bitField0_ |= 0x00000001;
                break;
              } // case 8
              case 16: {
                endTime_ = input.readInt32();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 26: {
                word_ = input.readStringRequireUtf8();
                bitField0_ |= 0x00000004;
                break;
              } // case 26
              case 37: {
                confidence_ = input.readFloat();
                bitField0_ |= 0x00000008;
                break;
              } // case 37
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private int startTime_ ;
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 start_time = 1;</code>
       * @return The startTime.
       */
      @Override
      public int getStartTime() {
        return startTime_;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 start_time = 1;</code>
       * @param value The startTime to set.
       * @return This builder for chaining.
       */
      public Builder setStartTime(int value) {

        startTime_ = value;
        bitField0_ |= 0x00000001;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 start_time = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000001);
        startTime_ = 0;
        onChanged();
        return this;
      }

      private int endTime_ ;
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 end_time = 2;</code>
       * @return The endTime.
       */
      @Override
      public int getEndTime() {
        return endTime_;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 end_time = 2;</code>
       * @param value The endTime to set.
       * @return This builder for chaining.
       */
      public Builder setEndTime(int value) {

        endTime_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>int32 end_time = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearEndTime() {
        bitField0_ = (bitField0_ & ~0x00000002);
        endTime_ = 0;
        onChanged();
        return this;
      }

      private Object word_ = "";
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>string word = 3;</code>
       * @return The word.
       */
      public String getWord() {
        Object ref = word_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          word_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>string word = 3;</code>
       * @return The bytes for word.
       */
      public com.google.protobuf.ByteString
          getWordBytes() {
        Object ref = word_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          word_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>string word = 3;</code>
       * @param value The word to set.
       * @return This builder for chaining.
       */
      public Builder setWord(
          String value) {
        if (value == null) { throw new NullPointerException(); }
        word_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>string word = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearWord() {
        word_ = getDefaultInstance().getWord();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>string word = 3;</code>
       * @param value The bytes for word to set.
       * @return This builder for chaining.
       */
      public Builder setWordBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) { throw new NullPointerException(); }
        checkByteStringIsUtf8(value);
        word_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }

      private float confidence_ ;
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number indicates an
       * estimated greater likelihood that the recognized words are correct. This
       * field is not guaranteed to be accurate and users should not rely on it to
       * be always provided. The default of 0.0 is a sentinel value indicating
       * confidence was not set. 
       * </pre>
       *
       * <code>float confidence = 4;</code>
       * @return The confidence.
       */
      @Override
      public float getConfidence() {
        return confidence_;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number indicates an
       * estimated greater likelihood that the recognized words are correct. This
       * field is not guaranteed to be accurate and users should not rely on it to
       * be always provided. The default of 0.0 is a sentinel value indicating
       * confidence was not set. 
       * </pre>
       *
       * <code>float confidence = 4;</code>
       * @param value The confidence to set.
       * @return This builder for chaining.
       */
      public Builder setConfidence(float value) {

        confidence_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number indicates an
       * estimated greater likelihood that the recognized words are correct. This
       * field is not guaranteed to be accurate and users should not rely on it to
       * be always provided. The default of 0.0 is a sentinel value indicating
       * confidence was not set. 
       * </pre>
       *
       * <code>float confidence = 4;</code>
       * @return This builder for chaining.
       */
      public Builder clearConfidence() {
        bitField0_ = (bitField0_ & ~0x00000008);
        confidence_ = 0F;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.WordInfo)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.WordInfo)
    private static final WordInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new WordInfo();
    }

    public static WordInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<WordInfo>
        PARSER = new com.google.protobuf.AbstractParser<WordInfo>() {
      @Override
      public WordInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<WordInfo> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<WordInfo> getParserForType() {
      return PARSER;
    }

    @Override
    public WordInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognizeResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognizeResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    java.util.List<StreamingRecognitionResult>
        getResultsList();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    StreamingRecognitionResult getResults(int index);
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    int getResultsCount();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    java.util.List<? extends StreamingRecognitionResultOrBuilder>
        getResultsOrBuilderList();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    StreamingRecognitionResultOrBuilder getResultsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeResponse}
   */
  public static final class StreamingRecognizeResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognizeResponse)
      StreamingRecognizeResponseOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingRecognizeResponse.newBuilder() to construct.
    private StreamingRecognizeResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognizeResponse() {
      results_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingRecognizeResponse();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              StreamingRecognizeResponse.class, Builder.class);
    }

    public static final int RESULTS_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<StreamingRecognitionResult> results_;
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    @Override
    public java.util.List<StreamingRecognitionResult> getResultsList() {
      return results_;
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    @Override
    public java.util.List<? extends StreamingRecognitionResultOrBuilder>
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    @Override
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    @Override
    public StreamingRecognitionResult getResults(int index) {
      return results_.get(index);
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple 
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    @Override
    public StreamingRecognitionResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(1, results_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < results_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, results_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof StreamingRecognizeResponse)) {
        return super.equals(obj);
      }
      StreamingRecognizeResponse other = (StreamingRecognizeResponse) obj;

      if (!getResultsList()
          .equals(other.getResultsList())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static StreamingRecognizeResponse parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeResponse parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognizeResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognizeResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognizeResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static StreamingRecognizeResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static StreamingRecognizeResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static StreamingRecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(StreamingRecognizeResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognizeResponse)
        StreamingRecognizeResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                StreamingRecognizeResponse.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.StreamingRecognizeResponse.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
        } else {
          results_ = null;
          resultsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
      }

      @Override
      public StreamingRecognizeResponse getDefaultInstanceForType() {
        return StreamingRecognizeResponse.getDefaultInstance();
      }

      @Override
      public StreamingRecognizeResponse build() {
        StreamingRecognizeResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public StreamingRecognizeResponse buildPartial() {
        StreamingRecognizeResponse result = new StreamingRecognizeResponse(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(StreamingRecognizeResponse result) {
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
      }

      private void buildPartial0(StreamingRecognizeResponse result) {
        int from_bitField0_ = bitField0_;
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof StreamingRecognizeResponse) {
          return mergeFrom((StreamingRecognizeResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(StreamingRecognizeResponse other) {
        if (other == StreamingRecognizeResponse.getDefaultInstance()) return this;
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                StreamingRecognitionResult m =
                    input.readMessage(
                        StreamingRecognitionResult.parser(),
                        extensionRegistry);
                if (resultsBuilder_ == null) {
                  ensureResultsIsMutable();
                  results_.add(m);
                } else {
                  resultsBuilder_.addMessage(m);
                }
                break;
              } // case 10
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<StreamingRecognitionResult> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          results_ = new java.util.ArrayList<StreamingRecognitionResult>(results_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          StreamingRecognitionResult, StreamingRecognitionResult.Builder, StreamingRecognitionResultOrBuilder> resultsBuilder_;

      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<StreamingRecognitionResult> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public StreamingRecognitionResult getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addAllResults(
          Iterable<? extends StreamingRecognitionResult> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public StreamingRecognitionResult.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public StreamingRecognitionResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<? extends StreamingRecognitionResultOrBuilder>
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public StreamingRecognitionResult.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            StreamingRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public StreamingRecognitionResult.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, StreamingRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple 
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<StreamingRecognitionResult.Builder>
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          StreamingRecognitionResult, StreamingRecognitionResult.Builder, StreamingRecognitionResultOrBuilder>
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              StreamingRecognitionResult, StreamingRecognitionResult.Builder, StreamingRecognitionResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognizeResponse)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognizeResponse)
    private static final StreamingRecognizeResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new StreamingRecognizeResponse();
    }

    public static StreamingRecognizeResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognizeResponse>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognizeResponse>() {
      @Override
      public StreamingRecognizeResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognizeResponse> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingRecognizeResponse> getParserForType() {
      return PARSER;
    }

    @Override
    public StreamingRecognizeResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognitionResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognitionResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<SpeechRecognitionAlternative>
        getAlternativesList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    SpeechRecognitionAlternative getAlternatives(int index);
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    int getAlternativesCount();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
        getAlternativesOrBuilderList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index);

    /**
     * <pre>
     * If `false`, this `StreamingRecognitionResult` represents an
     * interim result that may change. If `true`, this is the final time the
     * speech service will return this particular `StreamingRecognitionResult`,
     * the recognizer will not return any further hypotheses for this portion of
     * the transcript and corresponding audio.
     * </pre>
     *
     * <code>bool is_final = 2;</code>
     * @return The isFinal.
     */
    boolean getIsFinal();

    /**
     * <pre>
     * An estimate of the likelihood that the recognizer will not
     * change its guess about this interim result. Values range from 0.0
     * (completely unstable) to 1.0 (completely stable).
     * This field is only provided for interim results (`is_final=false`).
     * The default of 0.0 is a sentinel value indicating `stability` was not set.
     * </pre>
     *
     * <code>float stability = 3;</code>
     * @return The stability.
     */
    float getStability();

    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>int32 channel_tag = 5;</code>
     * @return The channelTag.
     */
    int getChannelTag();

    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>float audio_processed = 6;</code>
     * @return The audioProcessed.
     */
    float getAudioProcessed();
  }
  /**
   * <pre>
   * A streaming speech recognition result corresponding to a portion of the audio
   * that is currently being processed.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionResult}
   */
  public static final class StreamingRecognitionResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognitionResult)
      StreamingRecognitionResultOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StreamingRecognitionResult.newBuilder() to construct.
    private StreamingRecognitionResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognitionResult() {
      alternatives_ = java.util.Collections.emptyList();
    }

    @Override
    @SuppressWarnings({"unused"})
    protected Object newInstance(
        UnusedPrivateParameter unused) {
      return new StreamingRecognitionResult();
    }

    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
    }

    @Override
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              StreamingRecognitionResult.class, Builder.class);
    }

    public static final int ALTERNATIVES_FIELD_NUMBER = 1;
    @SuppressWarnings("serial")
    private java.util.List<SpeechRecognitionAlternative> alternatives_;
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public java.util.List<SpeechRecognitionAlternative> getAlternativesList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
        getAlternativesOrBuilderList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public int getAlternativesCount() {
      return alternatives_.size();
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public SpeechRecognitionAlternative getAlternatives(int index) {
      return alternatives_.get(index);
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    @Override
    public SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index) {
      return alternatives_.get(index);
    }

    public static final int IS_FINAL_FIELD_NUMBER = 2;
    private boolean isFinal_ = false;
    /**
     * <pre>
     * If `false`, this `StreamingRecognitionResult` represents an
     * interim result that may change. If `true`, this is the final time the
     * speech service will return this particular `StreamingRecognitionResult`,
     * the recognizer will not return any further hypotheses for this portion of
     * the transcript and corresponding audio.
     * </pre>
     *
     * <code>bool is_final = 2;</code>
     * @return The isFinal.
     */
    @Override
    public boolean getIsFinal() {
      return isFinal_;
    }

    public static final int STABILITY_FIELD_NUMBER = 3;
    private float stability_ = 0F;
    /**
     * <pre>
     * An estimate of the likelihood that the recognizer will not
     * change its guess about this interim result. Values range from 0.0
     * (completely unstable) to 1.0 (completely stable).
     * This field is only provided for interim results (`is_final=false`).
     * The default of 0.0 is a sentinel value indicating `stability` was not set.
     * </pre>
     *
     * <code>float stability = 3;</code>
     * @return The stability.
     */
    @Override
    public float getStability() {
      return stability_;
    }

    public static final int CHANNEL_TAG_FIELD_NUMBER = 5;
    private int channelTag_ = 0;
    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>int32 channel_tag = 5;</code>
     * @return The channelTag.
     */
    @Override
    public int getChannelTag() {
      return channelTag_;
    }

    public static final int AUDIO_PROCESSED_FIELD_NUMBER = 6;
    private float audioProcessed_ = 0F;
    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>float audio_processed = 6;</code>
     * @return The audioProcessed.
     */
    @Override
    public float getAudioProcessed() {
      return audioProcessed_;
    }

    private byte memoizedIsInitialized = -1;
    @Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < alternatives_.size(); i++) {
        output.writeMessage(1, alternatives_.get(i));
      }
      if (isFinal_ != false) {
        output.writeBool(2, isFinal_);
      }
      if (Float.floatToRawIntBits(stability_) != 0) {
        output.writeFloat(3, stability_);
      }
      if (channelTag_ != 0) {
        output.writeInt32(5, channelTag_);
      }
      if (Float.floatToRawIntBits(audioProcessed_) != 0) {
        output.writeFloat(6, audioProcessed_);
      }
      getUnknownFields().writeTo(output);
    }

    @Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < alternatives_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, alternatives_.get(i));
      }
      if (isFinal_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isFinal_);
      }
      if (Float.floatToRawIntBits(stability_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, stability_);
      }
      if (channelTag_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, channelTag_);
      }
      if (Float.floatToRawIntBits(audioProcessed_) != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(6, audioProcessed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof StreamingRecognitionResult)) {
        return super.equals(obj);
      }
      StreamingRecognitionResult other = (StreamingRecognitionResult) obj;

      if (!getAlternativesList()
          .equals(other.getAlternativesList())) return false;
      if (getIsFinal()
          != other.getIsFinal()) return false;
      if (Float.floatToIntBits(getStability())
          != Float.floatToIntBits(
              other.getStability())) return false;
      if (getChannelTag()
          != other.getChannelTag()) return false;
      if (Float.floatToIntBits(getAudioProcessed())
          != Float.floatToIntBits(
              other.getAudioProcessed())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getAlternativesCount() > 0) {
        hash = (37 * hash) + ALTERNATIVES_FIELD_NUMBER;
        hash = (53 * hash) + getAlternativesList().hashCode();
      }
      hash = (37 * hash) + IS_FINAL_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsFinal());
      hash = (37 * hash) + STABILITY_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getStability());
      hash = (37 * hash) + CHANNEL_TAG_FIELD_NUMBER;
      hash = (53 * hash) + getChannelTag();
      hash = (37 * hash) + AUDIO_PROCESSED_FIELD_NUMBER;
      hash = (53 * hash) + Float.floatToIntBits(
          getAudioProcessed());
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static StreamingRecognitionResult parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionResult parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static StreamingRecognitionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static StreamingRecognitionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognitionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public static StreamingRecognitionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }

    public static StreamingRecognitionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static StreamingRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static StreamingRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(StreamingRecognitionResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A streaming speech recognition result corresponding to a portion of the audio
     * that is currently being processed.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognitionResult)
        StreamingRecognitionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
      }

      @Override
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                StreamingRecognitionResult.class, Builder.class);
      }

      // Construct using riva.asr.riva.RivaAsr.StreamingRecognitionResult.newBuilder()
      private Builder() {

      }

      private Builder(
          BuilderParent parent) {
        super(parent);

      }
      @Override
      public Builder clear() {
        super.clear();
        bitField0_ = 0;
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
        } else {
          alternatives_ = null;
          alternativesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        isFinal_ = false;
        stability_ = 0F;
        channelTag_ = 0;
        audioProcessed_ = 0F;
        return this;
      }

      @Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
      }

      @Override
      public StreamingRecognitionResult getDefaultInstanceForType() {
        return StreamingRecognitionResult.getDefaultInstance();
      }

      @Override
      public StreamingRecognitionResult build() {
        StreamingRecognitionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @Override
      public StreamingRecognitionResult buildPartial() {
        StreamingRecognitionResult result = new StreamingRecognitionResult(this);
        buildPartialRepeatedFields(result);
        if (bitField0_ != 0) { buildPartial0(result); }
        onBuilt();
        return result;
      }

      private void buildPartialRepeatedFields(StreamingRecognitionResult result) {
        if (alternativesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) != 0)) {
            alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.alternatives_ = alternatives_;
        } else {
          result.alternatives_ = alternativesBuilder_.build();
        }
      }

      private void buildPartial0(StreamingRecognitionResult result) {
        int from_bitField0_ = bitField0_;
        if (((from_bitField0_ & 0x00000002) != 0)) {
          result.isFinal_ = isFinal_;
        }
        if (((from_bitField0_ & 0x00000004) != 0)) {
          result.stability_ = stability_;
        }
        if (((from_bitField0_ & 0x00000008) != 0)) {
          result.channelTag_ = channelTag_;
        }
        if (((from_bitField0_ & 0x00000010) != 0)) {
          result.audioProcessed_ = audioProcessed_;
        }
      }

      @Override
      public Builder clone() {
        return super.clone();
      }
      @Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.setField(field, value);
      }
      @Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return super.addRepeatedField(field, value);
      }
      @Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof StreamingRecognitionResult) {
          return mergeFrom((StreamingRecognitionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(StreamingRecognitionResult other) {
        if (other == StreamingRecognitionResult.getDefaultInstance()) return this;
        if (alternativesBuilder_ == null) {
          if (!other.alternatives_.isEmpty()) {
            if (alternatives_.isEmpty()) {
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAlternativesIsMutable();
              alternatives_.addAll(other.alternatives_);
            }
            onChanged();
          }
        } else {
          if (!other.alternatives_.isEmpty()) {
            if (alternativesBuilder_.isEmpty()) {
              alternativesBuilder_.dispose();
              alternativesBuilder_ = null;
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
              alternativesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAlternativesFieldBuilder() : null;
            } else {
              alternativesBuilder_.addAllMessages(other.alternatives_);
            }
          }
        }
        if (other.getIsFinal() != false) {
          setIsFinal(other.getIsFinal());
        }
        if (other.getStability() != 0F) {
          setStability(other.getStability());
        }
        if (other.getChannelTag() != 0) {
          setChannelTag(other.getChannelTag());
        }
        if (other.getAudioProcessed() != 0F) {
          setAudioProcessed(other.getAudioProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @Override
      public final boolean isInitialized() {
        return true;
      }

      @Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                SpeechRecognitionAlternative m =
                    input.readMessage(
                        SpeechRecognitionAlternative.parser(),
                        extensionRegistry);
                if (alternativesBuilder_ == null) {
                  ensureAlternativesIsMutable();
                  alternatives_.add(m);
                } else {
                  alternativesBuilder_.addMessage(m);
                }
                break;
              } // case 10
              case 16: {
                isFinal_ = input.readBool();
                bitField0_ |= 0x00000002;
                break;
              } // case 16
              case 29: {
                stability_ = input.readFloat();
                bitField0_ |= 0x00000004;
                break;
              } // case 29
              case 40: {
                channelTag_ = input.readInt32();
                bitField0_ |= 0x00000008;
                break;
              } // case 40
              case 53: {
                audioProcessed_ = input.readFloat();
                bitField0_ |= 0x00000010;
                break;
              } // case 53
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.util.List<SpeechRecognitionAlternative> alternatives_ =
        java.util.Collections.emptyList();
      private void ensureAlternativesIsMutable() {
        if (!((bitField0_ & 0x00000001) != 0)) {
          alternatives_ = new java.util.ArrayList<SpeechRecognitionAlternative>(alternatives_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder> alternativesBuilder_;

      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<SpeechRecognitionAlternative> getAlternativesList() {
        if (alternativesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(alternatives_);
        } else {
          return alternativesBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public int getAlternativesCount() {
        if (alternativesBuilder_ == null) {
          return alternatives_.size();
        } else {
          return alternativesBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative getAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);
        } else {
          return alternativesBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.set(index, value);
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.set(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(index, value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAllAlternatives(
          Iterable<? extends SpeechRecognitionAlternative> values) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, alternatives_);
          onChanged();
        } else {
          alternativesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder clearAlternatives() {
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          alternativesBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder removeAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.remove(index);
          onChanged();
        } else {
          alternativesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder getAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
          int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);  } else {
          return alternativesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<? extends SpeechRecognitionAlternativeOrBuilder>
           getAlternativesOrBuilderList() {
        if (alternativesBuilder_ != null) {
          return alternativesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(alternatives_);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder addAlternativesBuilder() {
        return getAlternativesFieldBuilder().addBuilder(
            SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public SpeechRecognitionAlternative.Builder addAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().addBuilder(
            index, SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<SpeechRecognitionAlternative.Builder>
           getAlternativesBuilderList() {
        return getAlternativesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder>
          getAlternativesFieldBuilder() {
        if (alternativesBuilder_ == null) {
          alternativesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              SpeechRecognitionAlternative, SpeechRecognitionAlternative.Builder, SpeechRecognitionAlternativeOrBuilder>(
                  alternatives_,
                  ((bitField0_ & 0x00000001) != 0),
                  getParentForChildren(),
                  isClean());
          alternatives_ = null;
        }
        return alternativesBuilder_;
      }

      private boolean isFinal_ ;
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>bool is_final = 2;</code>
       * @return The isFinal.
       */
      @Override
      public boolean getIsFinal() {
        return isFinal_;
      }
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>bool is_final = 2;</code>
       * @param value The isFinal to set.
       * @return This builder for chaining.
       */
      public Builder setIsFinal(boolean value) {

        isFinal_ = value;
        bitField0_ |= 0x00000002;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>bool is_final = 2;</code>
       * @return This builder for chaining.
       */
      public Builder clearIsFinal() {
        bitField0_ = (bitField0_ & ~0x00000002);
        isFinal_ = false;
        onChanged();
        return this;
      }

      private float stability_ ;
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>float stability = 3;</code>
       * @return The stability.
       */
      @Override
      public float getStability() {
        return stability_;
      }
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>float stability = 3;</code>
       * @param value The stability to set.
       * @return This builder for chaining.
       */
      public Builder setStability(float value) {

        stability_ = value;
        bitField0_ |= 0x00000004;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>float stability = 3;</code>
       * @return This builder for chaining.
       */
      public Builder clearStability() {
        bitField0_ = (bitField0_ & ~0x00000004);
        stability_ = 0F;
        onChanged();
        return this;
      }

      private int channelTag_ ;
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 5;</code>
       * @return The channelTag.
       */
      @Override
      public int getChannelTag() {
        return channelTag_;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 5;</code>
       * @param value The channelTag to set.
       * @return This builder for chaining.
       */
      public Builder setChannelTag(int value) {

        channelTag_ = value;
        bitField0_ |= 0x00000008;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>int32 channel_tag = 5;</code>
       * @return This builder for chaining.
       */
      public Builder clearChannelTag() {
        bitField0_ = (bitField0_ & ~0x00000008);
        channelTag_ = 0;
        onChanged();
        return this;
      }

      private float audioProcessed_ ;
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 6;</code>
       * @return The audioProcessed.
       */
      @Override
      public float getAudioProcessed() {
        return audioProcessed_;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 6;</code>
       * @param value The audioProcessed to set.
       * @return This builder for chaining.
       */
      public Builder setAudioProcessed(float value) {

        audioProcessed_ = value;
        bitField0_ |= 0x00000010;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>float audio_processed = 6;</code>
       * @return This builder for chaining.
       */
      public Builder clearAudioProcessed() {
        bitField0_ = (bitField0_ & ~0x00000010);
        audioProcessed_ = 0F;
        onChanged();
        return this;
      }
      @Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognitionResult)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognitionResult)
    private static final StreamingRecognitionResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new StreamingRecognitionResult();
    }

    public static StreamingRecognitionResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognitionResult>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognitionResult>() {
      @Override
      public StreamingRecognitionResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognitionResult> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<StreamingRecognitionResult> getParserForType() {
      return PARSER;
    }

    @Override
    public StreamingRecognitionResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_SpeechContext_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_SpeechContext_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_WordInfo_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    String[] descriptorData = {
      "\n\023riva/riva_asr.proto\022\017nvidia.riva.asr\032\025" +
              "riva/riva_audio.proto\"U\n\020RecognizeReques" +
      "t\0222\n\006config\030\001 \001(\0132\".nvidia.riva.asr.Reco" +
      "gnitionConfig\022\r\n\005audio\030\002 \001(\014\"\222\001\n\031Streami" +
      "ngRecognizeRequest\022G\n\020streaming_config\030\001" +
      " \001(\0132+.nvidia.riva.asr.StreamingRecognit" +
      "ionConfigH\000\022\027\n\raudio_content\030\002 \001(\014H\000B\023\n\021" +
      "streaming_request\"\272\004\n\021RecognitionConfig\022" +
      ",\n\010encoding\030\001 \001(\0162\032.nvidia.riva.AudioEnc" +
      "oding\022\031\n\021sample_rate_hertz\030\002 \001(\005\022\025\n\rlang" +
      "uage_code\030\003 \001(\t\022\030\n\020max_alternatives\030\004 \001(" +
      "\005\022\030\n\020profanity_filter\030\005 \001(\010\0227\n\017speech_co" +
      "ntexts\030\006 \003(\0132\036.nvidia.riva.asr.SpeechCon" +
      "text\022\033\n\023audio_channel_count\030\007 \001(\005\022 \n\030ena" +
      "ble_word_time_offsets\030\010 \001(\010\022$\n\034enable_au" +
      "tomatic_punctuation\030\013 \001(\010\022/\n\'enable_sepa" +
      "rate_recognition_per_channel\030\014 \001(\010\022\r\n\005mo" +
      "del\030\r \001(\t\022\034\n\024verbatim_transcripts\030\016 \001(\010\022" +
      "Y\n\024custom_configuration\030\030 \003(\0132;.nvidia.r" +
      "iva.asr.RecognitionConfig.CustomConfigur" +
      "ationEntry\032:\n\030CustomConfigurationEntry\022\013" +
      "\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\"i\n\032Stream" +
      "ingRecognitionConfig\0222\n\006config\030\001 \001(\0132\".n" +
      "vidia.riva.asr.RecognitionConfig\022\027\n\017inte" +
      "rim_results\030\002 \001(\010\"/\n\rSpeechContext\022\017\n\007ph" +
      "rases\030\001 \003(\t\022\r\n\005boost\030\004 \001(\002\"N\n\021RecognizeR" +
      "esponse\0229\n\007results\030\001 \003(\0132(.nvidia.riva.a" +
      "sr.SpeechRecognitionResult\"\214\001\n\027SpeechRec" +
      "ognitionResult\022C\n\014alternatives\030\001 \003(\0132-.n" +
      "vidia.riva.asr.SpeechRecognitionAlternat" +
      "ive\022\023\n\013channel_tag\030\002 \001(\005\022\027\n\017audio_proces" +
      "sed\030\003 \001(\002\"p\n\034SpeechRecognitionAlternativ" +
      "e\022\022\n\ntranscript\030\001 \001(\t\022\022\n\nconfidence\030\002 \001(" +
      "\002\022(\n\005words\030\003 \003(\0132\031.nvidia.riva.asr.WordI" +
      "nfo\"R\n\010WordInfo\022\022\n\nstart_time\030\001 \001(\005\022\020\n\010e" +
      "nd_time\030\002 \001(\005\022\014\n\004word\030\003 \001(\t\022\022\n\nconfidenc" +
      "e\030\004 \001(\002\"Z\n\032StreamingRecognizeResponse\022<\n" +
      "\007results\030\001 \003(\0132+.nvidia.riva.asr.Streami" +
      "ngRecognitionResult\"\264\001\n\032StreamingRecogni" +
      "tionResult\022C\n\014alternatives\030\001 \003(\0132-.nvidi" +
      "a.riva.asr.SpeechRecognitionAlternative\022" +
      "\020\n\010is_final\030\002 \001(\010\022\021\n\tstability\030\003 \001(\002\022\023\n\013" +
      "channel_tag\030\005 \001(\005\022\027\n\017audio_processed\030\006 \001" +
      "(\0022\342\001\n\025RivaSpeechRecognition\022T\n\tRecogniz" +
      "e\022!.nvidia.riva.asr.RecognizeRequest\032\".n" +
      "vidia.riva.asr.RecognizeResponse\"\000\022s\n\022St" +
      "reamingRecognize\022*.nvidia.riva.asr.Strea" +
      "mingRecognizeRequest\032+.nvidia.riva.asr.S" +
      "treamingRecognizeResponse\"\000(\0010\001B\033Z\026nvidi" +
      "a.com/riva_speech\370\001\001b\006proto3"
    };
    descriptor = com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          RivaAudio.getDescriptor(),
        });
    internal_static_nvidia_riva_asr_RecognizeRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognizeRequest_descriptor,
        new String[] { "Config", "Audio", });
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor,
        new String[] { "StreamingConfig", "AudioContent", "StreamingRequest", });
    internal_static_nvidia_riva_asr_RecognitionConfig_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognitionConfig_descriptor,
        new String[] { "Encoding", "SampleRateHertz", "LanguageCode", "MaxAlternatives", "ProfanityFilter", "SpeechContexts", "AudioChannelCount", "EnableWordTimeOffsets", "EnableAutomaticPunctuation", "EnableSeparateRecognitionPerChannel", "Model", "VerbatimTranscripts", "CustomConfiguration", });
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor =
      internal_static_nvidia_riva_asr_RecognitionConfig_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor,
        new String[] { "Config", "InterimResults", });
    internal_static_nvidia_riva_asr_SpeechContext_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_nvidia_riva_asr_SpeechContext_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_SpeechContext_descriptor,
        new String[] { "Phrases", "Boost", });
    internal_static_nvidia_riva_asr_RecognizeResponse_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognizeResponse_descriptor,
        new String[] { "Results", });
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor,
        new String[] { "Alternatives", "ChannelTag", "AudioProcessed", });
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor,
        new String[] { "Transcript", "Confidence", "Words", });
    internal_static_nvidia_riva_asr_WordInfo_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_WordInfo_descriptor,
        new String[] { "StartTime", "EndTime", "Word", "Confidence", });
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor,
        new String[] { "Results", });
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor,
        new String[] { "Alternatives", "IsFinal", "Stability", "ChannelTag", "AudioProcessed", });
    RivaAudio.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
